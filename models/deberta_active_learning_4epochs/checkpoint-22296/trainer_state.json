{
  "best_metric": 0.24108606576919556,
  "best_model_checkpoint": "/Users/deaxhavara/CyberPrint/models/deberta_active_learning_4epochs/checkpoint-5574",
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 22296,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00897021887334051,
      "grad_norm": 2.702097177505493,
      "learning_rate": 1e-05,
      "loss": 1.3363,
      "step": 50
    },
    {
      "epoch": 0.01794043774668102,
      "grad_norm": 3.207737445831299,
      "learning_rate": 2e-05,
      "loss": 0.528,
      "step": 100
    },
    {
      "epoch": 0.02691065662002153,
      "grad_norm": 5.6960530281066895,
      "learning_rate": 1.995494683726798e-05,
      "loss": 0.4697,
      "step": 150
    },
    {
      "epoch": 0.03588087549336204,
      "grad_norm": 6.509079456329346,
      "learning_rate": 1.9909893674535953e-05,
      "loss": 0.4943,
      "step": 200
    },
    {
      "epoch": 0.044851094366702544,
      "grad_norm": 0.3150832951068878,
      "learning_rate": 1.986484051180393e-05,
      "loss": 0.4194,
      "step": 250
    },
    {
      "epoch": 0.05382131324004306,
      "grad_norm": 3.9901585578918457,
      "learning_rate": 1.9819787349071907e-05,
      "loss": 0.3837,
      "step": 300
    },
    {
      "epoch": 0.06279153211338356,
      "grad_norm": 2.65856671333313,
      "learning_rate": 1.9774734186339885e-05,
      "loss": 0.4311,
      "step": 350
    },
    {
      "epoch": 0.07176175098672408,
      "grad_norm": 1.8213614225387573,
      "learning_rate": 1.972968102360786e-05,
      "loss": 0.4034,
      "step": 400
    },
    {
      "epoch": 0.08073196986006459,
      "grad_norm": 1.6545324325561523,
      "learning_rate": 1.9684627860875836e-05,
      "loss": 0.3792,
      "step": 450
    },
    {
      "epoch": 0.08970218873340509,
      "grad_norm": 9.279109001159668,
      "learning_rate": 1.963957469814381e-05,
      "loss": 0.5063,
      "step": 500
    },
    {
      "epoch": 0.0986724076067456,
      "grad_norm": 4.558069229125977,
      "learning_rate": 1.9594521535411787e-05,
      "loss": 0.3963,
      "step": 550
    },
    {
      "epoch": 0.10764262648008611,
      "grad_norm": 2.799372673034668,
      "learning_rate": 1.9549468372679764e-05,
      "loss": 0.4119,
      "step": 600
    },
    {
      "epoch": 0.11661284535342663,
      "grad_norm": 0.18441073596477509,
      "learning_rate": 1.950441520994774e-05,
      "loss": 0.3782,
      "step": 650
    },
    {
      "epoch": 0.12558306422676713,
      "grad_norm": 1.4779454469680786,
      "learning_rate": 1.9459362047215715e-05,
      "loss": 0.5457,
      "step": 700
    },
    {
      "epoch": 0.13455328310010764,
      "grad_norm": 5.437480926513672,
      "learning_rate": 1.9414308884483692e-05,
      "loss": 0.3528,
      "step": 750
    },
    {
      "epoch": 0.14352350197344815,
      "grad_norm": 0.17237906157970428,
      "learning_rate": 1.9369255721751666e-05,
      "loss": 0.3172,
      "step": 800
    },
    {
      "epoch": 0.15249372084678867,
      "grad_norm": 0.48419803380966187,
      "learning_rate": 1.9324202559019644e-05,
      "loss": 0.3194,
      "step": 850
    },
    {
      "epoch": 0.16146393972012918,
      "grad_norm": 1.2063528299331665,
      "learning_rate": 1.927914939628762e-05,
      "loss": 0.4105,
      "step": 900
    },
    {
      "epoch": 0.1704341585934697,
      "grad_norm": 0.24722041189670563,
      "learning_rate": 1.9234096233555598e-05,
      "loss": 0.3918,
      "step": 950
    },
    {
      "epoch": 0.17940437746681018,
      "grad_norm": 1.0287683010101318,
      "learning_rate": 1.9189043070823575e-05,
      "loss": 0.4377,
      "step": 1000
    },
    {
      "epoch": 0.1883745963401507,
      "grad_norm": 1.5569299459457397,
      "learning_rate": 1.914398990809155e-05,
      "loss": 0.4732,
      "step": 1050
    },
    {
      "epoch": 0.1973448152134912,
      "grad_norm": 3.0380561351776123,
      "learning_rate": 1.9098936745359527e-05,
      "loss": 0.3297,
      "step": 1100
    },
    {
      "epoch": 0.20631503408683172,
      "grad_norm": 12.682655334472656,
      "learning_rate": 1.90538835826275e-05,
      "loss": 0.3495,
      "step": 1150
    },
    {
      "epoch": 0.21528525296017223,
      "grad_norm": 0.6852636933326721,
      "learning_rate": 1.9008830419895478e-05,
      "loss": 0.3232,
      "step": 1200
    },
    {
      "epoch": 0.22425547183351274,
      "grad_norm": 8.162595748901367,
      "learning_rate": 1.8963777257163455e-05,
      "loss": 0.2634,
      "step": 1250
    },
    {
      "epoch": 0.23322569070685326,
      "grad_norm": 3.178480625152588,
      "learning_rate": 1.8918724094431432e-05,
      "loss": 0.3669,
      "step": 1300
    },
    {
      "epoch": 0.24219590958019377,
      "grad_norm": 0.095413938164711,
      "learning_rate": 1.8873670931699406e-05,
      "loss": 0.2592,
      "step": 1350
    },
    {
      "epoch": 0.25116612845353425,
      "grad_norm": 14.163515090942383,
      "learning_rate": 1.8828617768967383e-05,
      "loss": 0.3767,
      "step": 1400
    },
    {
      "epoch": 0.2601363473268748,
      "grad_norm": 4.329550743103027,
      "learning_rate": 1.8783564606235357e-05,
      "loss": 0.3447,
      "step": 1450
    },
    {
      "epoch": 0.2691065662002153,
      "grad_norm": 2.2264509201049805,
      "learning_rate": 1.8738511443503334e-05,
      "loss": 0.3215,
      "step": 1500
    },
    {
      "epoch": 0.2780767850735558,
      "grad_norm": 0.618263304233551,
      "learning_rate": 1.8693458280771312e-05,
      "loss": 0.3377,
      "step": 1550
    },
    {
      "epoch": 0.2870470039468963,
      "grad_norm": 0.13868200778961182,
      "learning_rate": 1.864840511803929e-05,
      "loss": 0.3316,
      "step": 1600
    },
    {
      "epoch": 0.2960172228202368,
      "grad_norm": 0.24608953297138214,
      "learning_rate": 1.8603351955307266e-05,
      "loss": 0.3398,
      "step": 1650
    },
    {
      "epoch": 0.30498744169357733,
      "grad_norm": 18.889863967895508,
      "learning_rate": 1.855829879257524e-05,
      "loss": 0.3141,
      "step": 1700
    },
    {
      "epoch": 0.3139576605669178,
      "grad_norm": 2.6987342834472656,
      "learning_rate": 1.8513245629843217e-05,
      "loss": 0.2669,
      "step": 1750
    },
    {
      "epoch": 0.32292787944025836,
      "grad_norm": 6.051609516143799,
      "learning_rate": 1.846819246711119e-05,
      "loss": 0.3228,
      "step": 1800
    },
    {
      "epoch": 0.33189809831359884,
      "grad_norm": 1.0494860410690308,
      "learning_rate": 1.842313930437917e-05,
      "loss": 0.2983,
      "step": 1850
    },
    {
      "epoch": 0.3408683171869394,
      "grad_norm": 7.30696439743042,
      "learning_rate": 1.8378086141647146e-05,
      "loss": 0.3492,
      "step": 1900
    },
    {
      "epoch": 0.34983853606027987,
      "grad_norm": 17.686969757080078,
      "learning_rate": 1.8333032978915123e-05,
      "loss": 0.2673,
      "step": 1950
    },
    {
      "epoch": 0.35880875493362036,
      "grad_norm": 0.7223127484321594,
      "learning_rate": 1.8287979816183097e-05,
      "loss": 0.3028,
      "step": 2000
    },
    {
      "epoch": 0.3677789738069609,
      "grad_norm": 4.49629545211792,
      "learning_rate": 1.8242926653451074e-05,
      "loss": 0.2941,
      "step": 2050
    },
    {
      "epoch": 0.3767491926803014,
      "grad_norm": 0.6253957748413086,
      "learning_rate": 1.8197873490719048e-05,
      "loss": 0.2698,
      "step": 2100
    },
    {
      "epoch": 0.3857194115536419,
      "grad_norm": 8.131208419799805,
      "learning_rate": 1.8152820327987025e-05,
      "loss": 0.2908,
      "step": 2150
    },
    {
      "epoch": 0.3946896304269824,
      "grad_norm": 0.5654251575469971,
      "learning_rate": 1.8107767165255003e-05,
      "loss": 0.3161,
      "step": 2200
    },
    {
      "epoch": 0.40365984930032295,
      "grad_norm": 14.034560203552246,
      "learning_rate": 1.806271400252298e-05,
      "loss": 0.3605,
      "step": 2250
    },
    {
      "epoch": 0.41263006817366343,
      "grad_norm": 5.765153408050537,
      "learning_rate": 1.8017660839790957e-05,
      "loss": 0.2494,
      "step": 2300
    },
    {
      "epoch": 0.421600287047004,
      "grad_norm": 2.5934650897979736,
      "learning_rate": 1.797260767705893e-05,
      "loss": 0.3638,
      "step": 2350
    },
    {
      "epoch": 0.43057050592034446,
      "grad_norm": 7.210143089294434,
      "learning_rate": 1.7927554514326908e-05,
      "loss": 0.3307,
      "step": 2400
    },
    {
      "epoch": 0.43954072479368494,
      "grad_norm": 0.8090410232543945,
      "learning_rate": 1.7882501351594882e-05,
      "loss": 0.2957,
      "step": 2450
    },
    {
      "epoch": 0.4485109436670255,
      "grad_norm": 6.318236827850342,
      "learning_rate": 1.783744818886286e-05,
      "loss": 0.2441,
      "step": 2500
    },
    {
      "epoch": 0.45748116254036597,
      "grad_norm": 3.7241618633270264,
      "learning_rate": 1.7792395026130837e-05,
      "loss": 0.3036,
      "step": 2550
    },
    {
      "epoch": 0.4664513814137065,
      "grad_norm": 0.2737427055835724,
      "learning_rate": 1.7747341863398814e-05,
      "loss": 0.3124,
      "step": 2600
    },
    {
      "epoch": 0.475421600287047,
      "grad_norm": 5.6152119636535645,
      "learning_rate": 1.7702288700666788e-05,
      "loss": 0.2904,
      "step": 2650
    },
    {
      "epoch": 0.48439181916038754,
      "grad_norm": 8.91226577758789,
      "learning_rate": 1.7657235537934765e-05,
      "loss": 0.3072,
      "step": 2700
    },
    {
      "epoch": 0.493362038033728,
      "grad_norm": 0.635953426361084,
      "learning_rate": 1.761218237520274e-05,
      "loss": 0.2823,
      "step": 2750
    },
    {
      "epoch": 0.5023322569070685,
      "grad_norm": 24.113725662231445,
      "learning_rate": 1.7567129212470716e-05,
      "loss": 0.2841,
      "step": 2800
    },
    {
      "epoch": 0.511302475780409,
      "grad_norm": 3.823387384414673,
      "learning_rate": 1.7522076049738693e-05,
      "loss": 0.2927,
      "step": 2850
    },
    {
      "epoch": 0.5202726946537496,
      "grad_norm": 8.231597900390625,
      "learning_rate": 1.747702288700667e-05,
      "loss": 0.3121,
      "step": 2900
    },
    {
      "epoch": 0.5292429135270901,
      "grad_norm": 0.6271505355834961,
      "learning_rate": 1.7431969724274645e-05,
      "loss": 0.2318,
      "step": 2950
    },
    {
      "epoch": 0.5382131324004306,
      "grad_norm": 8.019207954406738,
      "learning_rate": 1.7386916561542622e-05,
      "loss": 0.3347,
      "step": 3000
    },
    {
      "epoch": 0.547183351273771,
      "grad_norm": 5.837894916534424,
      "learning_rate": 1.73418633988106e-05,
      "loss": 0.2254,
      "step": 3050
    },
    {
      "epoch": 0.5561535701471116,
      "grad_norm": 0.6247704029083252,
      "learning_rate": 1.7296810236078573e-05,
      "loss": 0.274,
      "step": 3100
    },
    {
      "epoch": 0.5651237890204521,
      "grad_norm": 14.416746139526367,
      "learning_rate": 1.725175707334655e-05,
      "loss": 0.2868,
      "step": 3150
    },
    {
      "epoch": 0.5740940078937926,
      "grad_norm": 0.12553977966308594,
      "learning_rate": 1.7206703910614527e-05,
      "loss": 0.304,
      "step": 3200
    },
    {
      "epoch": 0.5830642267671331,
      "grad_norm": 5.3339524269104,
      "learning_rate": 1.7161650747882505e-05,
      "loss": 0.2207,
      "step": 3250
    },
    {
      "epoch": 0.5920344456404736,
      "grad_norm": 0.5094115138053894,
      "learning_rate": 1.711659758515048e-05,
      "loss": 0.2867,
      "step": 3300
    },
    {
      "epoch": 0.6010046645138142,
      "grad_norm": 1.035821557044983,
      "learning_rate": 1.7071544422418456e-05,
      "loss": 0.276,
      "step": 3350
    },
    {
      "epoch": 0.6099748833871547,
      "grad_norm": 0.37231549620628357,
      "learning_rate": 1.702649125968643e-05,
      "loss": 0.3112,
      "step": 3400
    },
    {
      "epoch": 0.6189451022604952,
      "grad_norm": 3.5317745208740234,
      "learning_rate": 1.6981438096954407e-05,
      "loss": 0.2628,
      "step": 3450
    },
    {
      "epoch": 0.6279153211338356,
      "grad_norm": 0.9512822031974792,
      "learning_rate": 1.6936384934222384e-05,
      "loss": 0.2684,
      "step": 3500
    },
    {
      "epoch": 0.6368855400071761,
      "grad_norm": 14.220170974731445,
      "learning_rate": 1.689133177149036e-05,
      "loss": 0.2896,
      "step": 3550
    },
    {
      "epoch": 0.6458557588805167,
      "grad_norm": 4.559516429901123,
      "learning_rate": 1.6846278608758335e-05,
      "loss": 0.2514,
      "step": 3600
    },
    {
      "epoch": 0.6548259777538572,
      "grad_norm": 0.3705527186393738,
      "learning_rate": 1.6801225446026313e-05,
      "loss": 0.2397,
      "step": 3650
    },
    {
      "epoch": 0.6637961966271977,
      "grad_norm": 8.69636344909668,
      "learning_rate": 1.675617228329429e-05,
      "loss": 0.2556,
      "step": 3700
    },
    {
      "epoch": 0.6727664155005382,
      "grad_norm": 6.378554821014404,
      "learning_rate": 1.6711119120562264e-05,
      "loss": 0.255,
      "step": 3750
    },
    {
      "epoch": 0.6817366343738788,
      "grad_norm": 0.09609648585319519,
      "learning_rate": 1.666606595783024e-05,
      "loss": 0.2132,
      "step": 3800
    },
    {
      "epoch": 0.6907068532472193,
      "grad_norm": 0.2592240571975708,
      "learning_rate": 1.6621012795098218e-05,
      "loss": 0.2246,
      "step": 3850
    },
    {
      "epoch": 0.6996770721205597,
      "grad_norm": 11.132830619812012,
      "learning_rate": 1.6575959632366196e-05,
      "loss": 0.3281,
      "step": 3900
    },
    {
      "epoch": 0.7086472909939002,
      "grad_norm": 0.7787564992904663,
      "learning_rate": 1.653090646963417e-05,
      "loss": 0.3033,
      "step": 3950
    },
    {
      "epoch": 0.7176175098672407,
      "grad_norm": 0.18292640149593353,
      "learning_rate": 1.6485853306902147e-05,
      "loss": 0.2632,
      "step": 4000
    },
    {
      "epoch": 0.7265877287405813,
      "grad_norm": 5.6020894050598145,
      "learning_rate": 1.644080014417012e-05,
      "loss": 0.2889,
      "step": 4050
    },
    {
      "epoch": 0.7355579476139218,
      "grad_norm": 13.382370948791504,
      "learning_rate": 1.6395746981438098e-05,
      "loss": 0.2762,
      "step": 4100
    },
    {
      "epoch": 0.7445281664872623,
      "grad_norm": 0.7662826180458069,
      "learning_rate": 1.6350693818706075e-05,
      "loss": 0.1894,
      "step": 4150
    },
    {
      "epoch": 0.7534983853606028,
      "grad_norm": 4.966489791870117,
      "learning_rate": 1.6305640655974052e-05,
      "loss": 0.2468,
      "step": 4200
    },
    {
      "epoch": 0.7624686042339434,
      "grad_norm": 10.07754135131836,
      "learning_rate": 1.6260587493242026e-05,
      "loss": 0.2555,
      "step": 4250
    },
    {
      "epoch": 0.7714388231072838,
      "grad_norm": 14.49848461151123,
      "learning_rate": 1.6215534330510003e-05,
      "loss": 0.2958,
      "step": 4300
    },
    {
      "epoch": 0.7804090419806243,
      "grad_norm": 6.443771839141846,
      "learning_rate": 1.6170481167777977e-05,
      "loss": 0.3337,
      "step": 4350
    },
    {
      "epoch": 0.7893792608539648,
      "grad_norm": 0.08505465090274811,
      "learning_rate": 1.6125428005045955e-05,
      "loss": 0.2542,
      "step": 4400
    },
    {
      "epoch": 0.7983494797273053,
      "grad_norm": 1.369659185409546,
      "learning_rate": 1.6080374842313932e-05,
      "loss": 0.3351,
      "step": 4450
    },
    {
      "epoch": 0.8073196986006459,
      "grad_norm": 8.463960647583008,
      "learning_rate": 1.603532167958191e-05,
      "loss": 0.3074,
      "step": 4500
    },
    {
      "epoch": 0.8162899174739864,
      "grad_norm": 8.311412811279297,
      "learning_rate": 1.5990268516849886e-05,
      "loss": 0.3363,
      "step": 4550
    },
    {
      "epoch": 0.8252601363473269,
      "grad_norm": 0.8634010553359985,
      "learning_rate": 1.594521535411786e-05,
      "loss": 0.2241,
      "step": 4600
    },
    {
      "epoch": 0.8342303552206674,
      "grad_norm": 0.47254425287246704,
      "learning_rate": 1.5900162191385837e-05,
      "loss": 0.2477,
      "step": 4650
    },
    {
      "epoch": 0.843200574094008,
      "grad_norm": 7.443446636199951,
      "learning_rate": 1.585510902865381e-05,
      "loss": 0.2247,
      "step": 4700
    },
    {
      "epoch": 0.8521707929673484,
      "grad_norm": 12.395566940307617,
      "learning_rate": 1.581005586592179e-05,
      "loss": 0.249,
      "step": 4750
    },
    {
      "epoch": 0.8611410118406889,
      "grad_norm": 6.518298149108887,
      "learning_rate": 1.5765002703189766e-05,
      "loss": 0.2685,
      "step": 4800
    },
    {
      "epoch": 0.8701112307140294,
      "grad_norm": 1.4411507844924927,
      "learning_rate": 1.5719949540457743e-05,
      "loss": 0.2372,
      "step": 4850
    },
    {
      "epoch": 0.8790814495873699,
      "grad_norm": 0.5068363547325134,
      "learning_rate": 1.5674896377725717e-05,
      "loss": 0.2434,
      "step": 4900
    },
    {
      "epoch": 0.8880516684607105,
      "grad_norm": 1.7448986768722534,
      "learning_rate": 1.5629843214993694e-05,
      "loss": 0.3385,
      "step": 4950
    },
    {
      "epoch": 0.897021887334051,
      "grad_norm": 11.002448081970215,
      "learning_rate": 1.5584790052261668e-05,
      "loss": 0.2318,
      "step": 5000
    },
    {
      "epoch": 0.9059921062073915,
      "grad_norm": 0.07945325970649719,
      "learning_rate": 1.5539736889529645e-05,
      "loss": 0.2606,
      "step": 5050
    },
    {
      "epoch": 0.9149623250807319,
      "grad_norm": 4.8680572509765625,
      "learning_rate": 1.5494683726797623e-05,
      "loss": 0.3126,
      "step": 5100
    },
    {
      "epoch": 0.9239325439540724,
      "grad_norm": 10.44175910949707,
      "learning_rate": 1.54496305640656e-05,
      "loss": 0.2682,
      "step": 5150
    },
    {
      "epoch": 0.932902762827413,
      "grad_norm": 5.850577354431152,
      "learning_rate": 1.5404577401333577e-05,
      "loss": 0.1974,
      "step": 5200
    },
    {
      "epoch": 0.9418729817007535,
      "grad_norm": 5.697955131530762,
      "learning_rate": 1.535952423860155e-05,
      "loss": 0.2657,
      "step": 5250
    },
    {
      "epoch": 0.950843200574094,
      "grad_norm": 3.036616086959839,
      "learning_rate": 1.531447107586953e-05,
      "loss": 0.2068,
      "step": 5300
    },
    {
      "epoch": 0.9598134194474345,
      "grad_norm": 0.6340799331665039,
      "learning_rate": 1.5269417913137502e-05,
      "loss": 0.2728,
      "step": 5350
    },
    {
      "epoch": 0.9687836383207751,
      "grad_norm": 1.5117286443710327,
      "learning_rate": 1.5224364750405481e-05,
      "loss": 0.2254,
      "step": 5400
    },
    {
      "epoch": 0.9777538571941156,
      "grad_norm": 3.7969813346862793,
      "learning_rate": 1.5179311587673455e-05,
      "loss": 0.2808,
      "step": 5450
    },
    {
      "epoch": 0.986724076067456,
      "grad_norm": 5.875756740570068,
      "learning_rate": 1.5134258424941432e-05,
      "loss": 0.2528,
      "step": 5500
    },
    {
      "epoch": 0.9956942949407965,
      "grad_norm": 0.043137092143297195,
      "learning_rate": 1.5089205262209408e-05,
      "loss": 0.2065,
      "step": 5550
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9257265877287406,
      "eval_f1": 0.9271059693650966,
      "eval_loss": 0.24108606576919556,
      "eval_runtime": 1096.4788,
      "eval_samples_per_second": 10.167,
      "eval_sentiment_accuracy": 0.9257265877287406,
      "eval_steps_per_second": 1.271,
      "step": 5574
    },
    {
      "epoch": 1.004664513814137,
      "grad_norm": 5.913891315460205,
      "learning_rate": 1.5044152099477385e-05,
      "loss": 0.2458,
      "step": 5600
    },
    {
      "epoch": 1.0136347326874775,
      "grad_norm": 0.8428468704223633,
      "learning_rate": 1.499909893674536e-05,
      "loss": 0.2422,
      "step": 5650
    },
    {
      "epoch": 1.022604951560818,
      "grad_norm": 6.513350486755371,
      "learning_rate": 1.4954045774013338e-05,
      "loss": 0.2268,
      "step": 5700
    },
    {
      "epoch": 1.0315751704341587,
      "grad_norm": 0.3003607392311096,
      "learning_rate": 1.4908992611281312e-05,
      "loss": 0.213,
      "step": 5750
    },
    {
      "epoch": 1.0405453893074992,
      "grad_norm": 20.96712875366211,
      "learning_rate": 1.4863939448549289e-05,
      "loss": 0.2111,
      "step": 5800
    },
    {
      "epoch": 1.0495156081808397,
      "grad_norm": 4.303884983062744,
      "learning_rate": 1.4818886285817266e-05,
      "loss": 0.2696,
      "step": 5850
    },
    {
      "epoch": 1.0584858270541802,
      "grad_norm": 27.649232864379883,
      "learning_rate": 1.4773833123085242e-05,
      "loss": 0.212,
      "step": 5900
    },
    {
      "epoch": 1.0674560459275206,
      "grad_norm": 18.23099708557129,
      "learning_rate": 1.4728779960353219e-05,
      "loss": 0.2619,
      "step": 5950
    },
    {
      "epoch": 1.0764262648008611,
      "grad_norm": 3.6268532276153564,
      "learning_rate": 1.4683726797621195e-05,
      "loss": 0.3209,
      "step": 6000
    },
    {
      "epoch": 1.0853964836742016,
      "grad_norm": 11.002328872680664,
      "learning_rate": 1.4638673634889172e-05,
      "loss": 0.1506,
      "step": 6050
    },
    {
      "epoch": 1.094366702547542,
      "grad_norm": 0.1856272667646408,
      "learning_rate": 1.4593620472157146e-05,
      "loss": 0.2031,
      "step": 6100
    },
    {
      "epoch": 1.1033369214208826,
      "grad_norm": 0.2694563567638397,
      "learning_rate": 1.4548567309425123e-05,
      "loss": 0.2607,
      "step": 6150
    },
    {
      "epoch": 1.1123071402942233,
      "grad_norm": 19.575031280517578,
      "learning_rate": 1.4503514146693099e-05,
      "loss": 0.2185,
      "step": 6200
    },
    {
      "epoch": 1.1212773591675638,
      "grad_norm": 3.1305136680603027,
      "learning_rate": 1.4458460983961076e-05,
      "loss": 0.2094,
      "step": 6250
    },
    {
      "epoch": 1.1302475780409043,
      "grad_norm": 6.459532260894775,
      "learning_rate": 1.4413407821229052e-05,
      "loss": 0.2904,
      "step": 6300
    },
    {
      "epoch": 1.1392177969142447,
      "grad_norm": 5.720282077789307,
      "learning_rate": 1.4368354658497029e-05,
      "loss": 0.1259,
      "step": 6350
    },
    {
      "epoch": 1.1481880157875852,
      "grad_norm": 0.03537966310977936,
      "learning_rate": 1.4323301495765003e-05,
      "loss": 0.2045,
      "step": 6400
    },
    {
      "epoch": 1.1571582346609257,
      "grad_norm": 0.28379225730895996,
      "learning_rate": 1.427824833303298e-05,
      "loss": 0.1903,
      "step": 6450
    },
    {
      "epoch": 1.1661284535342662,
      "grad_norm": 4.35634183883667,
      "learning_rate": 1.4233195170300955e-05,
      "loss": 0.1671,
      "step": 6500
    },
    {
      "epoch": 1.1750986724076067,
      "grad_norm": 43.49384689331055,
      "learning_rate": 1.4188142007568933e-05,
      "loss": 0.2754,
      "step": 6550
    },
    {
      "epoch": 1.1840688912809472,
      "grad_norm": 0.051817476749420166,
      "learning_rate": 1.414308884483691e-05,
      "loss": 0.1736,
      "step": 6600
    },
    {
      "epoch": 1.1930391101542877,
      "grad_norm": 2.9912078380584717,
      "learning_rate": 1.4098035682104886e-05,
      "loss": 0.2906,
      "step": 6650
    },
    {
      "epoch": 1.2020093290276284,
      "grad_norm": 11.254371643066406,
      "learning_rate": 1.4052982519372861e-05,
      "loss": 0.228,
      "step": 6700
    },
    {
      "epoch": 1.2109795479009688,
      "grad_norm": 0.1371053159236908,
      "learning_rate": 1.4007929356640837e-05,
      "loss": 0.2571,
      "step": 6750
    },
    {
      "epoch": 1.2199497667743093,
      "grad_norm": 7.812307834625244,
      "learning_rate": 1.3962876193908814e-05,
      "loss": 0.2382,
      "step": 6800
    },
    {
      "epoch": 1.2289199856476498,
      "grad_norm": 1.0008546113967896,
      "learning_rate": 1.391782303117679e-05,
      "loss": 0.2013,
      "step": 6850
    },
    {
      "epoch": 1.2378902045209903,
      "grad_norm": 0.1312917321920395,
      "learning_rate": 1.3872769868444767e-05,
      "loss": 0.2195,
      "step": 6900
    },
    {
      "epoch": 1.2468604233943308,
      "grad_norm": 0.18049542605876923,
      "learning_rate": 1.3827716705712742e-05,
      "loss": 0.1536,
      "step": 6950
    },
    {
      "epoch": 1.2558306422676713,
      "grad_norm": 10.41403579711914,
      "learning_rate": 1.3782663542980718e-05,
      "loss": 0.1684,
      "step": 7000
    },
    {
      "epoch": 1.264800861141012,
      "grad_norm": 4.273346900939941,
      "learning_rate": 1.3737610380248693e-05,
      "loss": 0.272,
      "step": 7050
    },
    {
      "epoch": 1.2737710800143525,
      "grad_norm": 0.08045650273561478,
      "learning_rate": 1.369255721751667e-05,
      "loss": 0.1902,
      "step": 7100
    },
    {
      "epoch": 1.282741298887693,
      "grad_norm": 0.5068803429603577,
      "learning_rate": 1.3647504054784646e-05,
      "loss": 0.1604,
      "step": 7150
    },
    {
      "epoch": 1.2917115177610334,
      "grad_norm": 15.547286033630371,
      "learning_rate": 1.3602450892052624e-05,
      "loss": 0.2047,
      "step": 7200
    },
    {
      "epoch": 1.300681736634374,
      "grad_norm": 0.35583531856536865,
      "learning_rate": 1.35573977293206e-05,
      "loss": 0.1618,
      "step": 7250
    },
    {
      "epoch": 1.3096519555077144,
      "grad_norm": 0.019600749015808105,
      "learning_rate": 1.3512344566588575e-05,
      "loss": 0.1443,
      "step": 7300
    },
    {
      "epoch": 1.318622174381055,
      "grad_norm": 0.08168476074934006,
      "learning_rate": 1.3467291403856552e-05,
      "loss": 0.2448,
      "step": 7350
    },
    {
      "epoch": 1.3275923932543954,
      "grad_norm": 0.4994696378707886,
      "learning_rate": 1.3422238241124528e-05,
      "loss": 0.2037,
      "step": 7400
    },
    {
      "epoch": 1.3365626121277359,
      "grad_norm": 0.4527755677700043,
      "learning_rate": 1.3377185078392505e-05,
      "loss": 0.1977,
      "step": 7450
    },
    {
      "epoch": 1.3455328310010763,
      "grad_norm": 0.4208528399467468,
      "learning_rate": 1.333213191566048e-05,
      "loss": 0.2271,
      "step": 7500
    },
    {
      "epoch": 1.3545030498744168,
      "grad_norm": 0.024819865822792053,
      "learning_rate": 1.3287078752928458e-05,
      "loss": 0.2208,
      "step": 7550
    },
    {
      "epoch": 1.3634732687477573,
      "grad_norm": 0.2925812900066376,
      "learning_rate": 1.3242025590196431e-05,
      "loss": 0.2462,
      "step": 7600
    },
    {
      "epoch": 1.372443487621098,
      "grad_norm": 0.4145650863647461,
      "learning_rate": 1.3196972427464409e-05,
      "loss": 0.2343,
      "step": 7650
    },
    {
      "epoch": 1.3814137064944385,
      "grad_norm": 0.7458784580230713,
      "learning_rate": 1.3151919264732384e-05,
      "loss": 0.2431,
      "step": 7700
    },
    {
      "epoch": 1.390383925367779,
      "grad_norm": 0.42861104011535645,
      "learning_rate": 1.3106866102000362e-05,
      "loss": 0.2011,
      "step": 7750
    },
    {
      "epoch": 1.3993541442411195,
      "grad_norm": 28.26966094970703,
      "learning_rate": 1.3061812939268337e-05,
      "loss": 0.1707,
      "step": 7800
    },
    {
      "epoch": 1.40832436311446,
      "grad_norm": 0.22497843205928802,
      "learning_rate": 1.3016759776536314e-05,
      "loss": 0.2227,
      "step": 7850
    },
    {
      "epoch": 1.4172945819878005,
      "grad_norm": 0.029315222054719925,
      "learning_rate": 1.2971706613804288e-05,
      "loss": 0.1839,
      "step": 7900
    },
    {
      "epoch": 1.426264800861141,
      "grad_norm": 2.224693775177002,
      "learning_rate": 1.2926653451072266e-05,
      "loss": 0.1829,
      "step": 7950
    },
    {
      "epoch": 1.4352350197344816,
      "grad_norm": 12.835407257080078,
      "learning_rate": 1.2881600288340243e-05,
      "loss": 0.2229,
      "step": 8000
    },
    {
      "epoch": 1.4442052386078221,
      "grad_norm": 7.705463886260986,
      "learning_rate": 1.2836547125608218e-05,
      "loss": 0.271,
      "step": 8050
    },
    {
      "epoch": 1.4531754574811626,
      "grad_norm": 0.5256671905517578,
      "learning_rate": 1.2791493962876196e-05,
      "loss": 0.2138,
      "step": 8100
    },
    {
      "epoch": 1.462145676354503,
      "grad_norm": 0.33096253871917725,
      "learning_rate": 1.2746440800144171e-05,
      "loss": 0.246,
      "step": 8150
    },
    {
      "epoch": 1.4711158952278436,
      "grad_norm": 6.618458271026611,
      "learning_rate": 1.2701387637412148e-05,
      "loss": 0.193,
      "step": 8200
    },
    {
      "epoch": 1.480086114101184,
      "grad_norm": 20.436302185058594,
      "learning_rate": 1.2656334474680122e-05,
      "loss": 0.2612,
      "step": 8250
    },
    {
      "epoch": 1.4890563329745246,
      "grad_norm": 9.158504486083984,
      "learning_rate": 1.26112813119481e-05,
      "loss": 0.1929,
      "step": 8300
    },
    {
      "epoch": 1.498026551847865,
      "grad_norm": 3.2388763427734375,
      "learning_rate": 1.2566228149216075e-05,
      "loss": 0.2676,
      "step": 8350
    },
    {
      "epoch": 1.5069967707212055,
      "grad_norm": 22.97769546508789,
      "learning_rate": 1.2521174986484052e-05,
      "loss": 0.2512,
      "step": 8400
    },
    {
      "epoch": 1.515966989594546,
      "grad_norm": 9.677881240844727,
      "learning_rate": 1.2476121823752028e-05,
      "loss": 0.318,
      "step": 8450
    },
    {
      "epoch": 1.5249372084678865,
      "grad_norm": 0.06534922868013382,
      "learning_rate": 1.2431068661020005e-05,
      "loss": 0.2241,
      "step": 8500
    },
    {
      "epoch": 1.533907427341227,
      "grad_norm": 0.3531467318534851,
      "learning_rate": 1.2386015498287979e-05,
      "loss": 0.1707,
      "step": 8550
    },
    {
      "epoch": 1.5428776462145677,
      "grad_norm": 12.487276077270508,
      "learning_rate": 1.2340962335555956e-05,
      "loss": 0.236,
      "step": 8600
    },
    {
      "epoch": 1.5518478650879082,
      "grad_norm": 3.9972336292266846,
      "learning_rate": 1.2295909172823932e-05,
      "loss": 0.2887,
      "step": 8650
    },
    {
      "epoch": 1.5608180839612487,
      "grad_norm": 0.1899576485157013,
      "learning_rate": 1.225085601009191e-05,
      "loss": 0.2552,
      "step": 8700
    },
    {
      "epoch": 1.5697883028345891,
      "grad_norm": 0.023646052926778793,
      "learning_rate": 1.2205802847359886e-05,
      "loss": 0.1831,
      "step": 8750
    },
    {
      "epoch": 1.5787585217079296,
      "grad_norm": 2.0021255016326904,
      "learning_rate": 1.2160749684627862e-05,
      "loss": 0.257,
      "step": 8800
    },
    {
      "epoch": 1.5877287405812703,
      "grad_norm": 0.4614107310771942,
      "learning_rate": 1.211569652189584e-05,
      "loss": 0.2479,
      "step": 8850
    },
    {
      "epoch": 1.5966989594546108,
      "grad_norm": 3.560410737991333,
      "learning_rate": 1.2070643359163813e-05,
      "loss": 0.2179,
      "step": 8900
    },
    {
      "epoch": 1.6056691783279513,
      "grad_norm": 0.22520139813423157,
      "learning_rate": 1.202559019643179e-05,
      "loss": 0.2583,
      "step": 8950
    },
    {
      "epoch": 1.6146393972012918,
      "grad_norm": 11.366898536682129,
      "learning_rate": 1.1980537033699766e-05,
      "loss": 0.1926,
      "step": 9000
    },
    {
      "epoch": 1.6236096160746323,
      "grad_norm": 4.1376543045043945,
      "learning_rate": 1.1935483870967743e-05,
      "loss": 0.1591,
      "step": 9050
    },
    {
      "epoch": 1.6325798349479728,
      "grad_norm": 0.11177900433540344,
      "learning_rate": 1.1890430708235719e-05,
      "loss": 0.1688,
      "step": 9100
    },
    {
      "epoch": 1.6415500538213132,
      "grad_norm": 0.5110631585121155,
      "learning_rate": 1.1845377545503696e-05,
      "loss": 0.1981,
      "step": 9150
    },
    {
      "epoch": 1.6505202726946537,
      "grad_norm": 1.4657789468765259,
      "learning_rate": 1.180032438277167e-05,
      "loss": 0.2019,
      "step": 9200
    },
    {
      "epoch": 1.6594904915679942,
      "grad_norm": 0.07013824582099915,
      "learning_rate": 1.1755271220039647e-05,
      "loss": 0.264,
      "step": 9250
    },
    {
      "epoch": 1.6684607104413347,
      "grad_norm": 9.567301750183105,
      "learning_rate": 1.1710218057307623e-05,
      "loss": 0.2114,
      "step": 9300
    },
    {
      "epoch": 1.6774309293146752,
      "grad_norm": 7.0854997634887695,
      "learning_rate": 1.16651648945756e-05,
      "loss": 0.2637,
      "step": 9350
    },
    {
      "epoch": 1.6864011481880157,
      "grad_norm": 5.53441047668457,
      "learning_rate": 1.1620111731843577e-05,
      "loss": 0.3065,
      "step": 9400
    },
    {
      "epoch": 1.6953713670613562,
      "grad_norm": 18.87715721130371,
      "learning_rate": 1.1575058569111553e-05,
      "loss": 0.2452,
      "step": 9450
    },
    {
      "epoch": 1.7043415859346966,
      "grad_norm": 0.26853474974632263,
      "learning_rate": 1.153000540637953e-05,
      "loss": 0.1526,
      "step": 9500
    },
    {
      "epoch": 1.7133118048080374,
      "grad_norm": 5.800537586212158,
      "learning_rate": 1.1484952243647504e-05,
      "loss": 0.2393,
      "step": 9550
    },
    {
      "epoch": 1.7222820236813778,
      "grad_norm": 4.111152172088623,
      "learning_rate": 1.1439899080915481e-05,
      "loss": 0.2501,
      "step": 9600
    },
    {
      "epoch": 1.7312522425547183,
      "grad_norm": 1.4482810497283936,
      "learning_rate": 1.1394845918183457e-05,
      "loss": 0.2183,
      "step": 9650
    },
    {
      "epoch": 1.7402224614280588,
      "grad_norm": 0.1181921735405922,
      "learning_rate": 1.1349792755451434e-05,
      "loss": 0.2161,
      "step": 9700
    },
    {
      "epoch": 1.7491926803013995,
      "grad_norm": 0.28826501965522766,
      "learning_rate": 1.130473959271941e-05,
      "loss": 0.253,
      "step": 9750
    },
    {
      "epoch": 1.75816289917474,
      "grad_norm": 1.0541338920593262,
      "learning_rate": 1.1259686429987387e-05,
      "loss": 0.311,
      "step": 9800
    },
    {
      "epoch": 1.7671331180480805,
      "grad_norm": 0.9423807263374329,
      "learning_rate": 1.121463326725536e-05,
      "loss": 0.2036,
      "step": 9850
    },
    {
      "epoch": 1.776103336921421,
      "grad_norm": 0.7130033373832703,
      "learning_rate": 1.1169580104523338e-05,
      "loss": 0.2268,
      "step": 9900
    },
    {
      "epoch": 1.7850735557947615,
      "grad_norm": 3.7976620197296143,
      "learning_rate": 1.1124526941791314e-05,
      "loss": 0.122,
      "step": 9950
    },
    {
      "epoch": 1.794043774668102,
      "grad_norm": 3.56089448928833,
      "learning_rate": 1.1079473779059291e-05,
      "loss": 0.233,
      "step": 10000
    },
    {
      "epoch": 1.8030139935414424,
      "grad_norm": 0.029530135914683342,
      "learning_rate": 1.1034420616327266e-05,
      "loss": 0.2285,
      "step": 10050
    },
    {
      "epoch": 1.811984212414783,
      "grad_norm": 0.09194652736186981,
      "learning_rate": 1.0989367453595244e-05,
      "loss": 0.1486,
      "step": 10100
    },
    {
      "epoch": 1.8209544312881234,
      "grad_norm": 0.6807070374488831,
      "learning_rate": 1.0944314290863221e-05,
      "loss": 0.1856,
      "step": 10150
    },
    {
      "epoch": 1.8299246501614639,
      "grad_norm": 0.2869791090488434,
      "learning_rate": 1.0899261128131195e-05,
      "loss": 0.2238,
      "step": 10200
    },
    {
      "epoch": 1.8388948690348044,
      "grad_norm": 6.111999988555908,
      "learning_rate": 1.0854207965399172e-05,
      "loss": 0.2148,
      "step": 10250
    },
    {
      "epoch": 1.8478650879081449,
      "grad_norm": 0.2201208621263504,
      "learning_rate": 1.0809154802667148e-05,
      "loss": 0.2382,
      "step": 10300
    },
    {
      "epoch": 1.8568353067814853,
      "grad_norm": 2.381432294845581,
      "learning_rate": 1.0764101639935125e-05,
      "loss": 0.2157,
      "step": 10350
    },
    {
      "epoch": 1.8658055256548258,
      "grad_norm": 0.5649799108505249,
      "learning_rate": 1.07190484772031e-05,
      "loss": 0.2059,
      "step": 10400
    },
    {
      "epoch": 1.8747757445281665,
      "grad_norm": 0.04770003259181976,
      "learning_rate": 1.0673995314471078e-05,
      "loss": 0.1865,
      "step": 10450
    },
    {
      "epoch": 1.883745963401507,
      "grad_norm": 0.196303129196167,
      "learning_rate": 1.0628942151739052e-05,
      "loss": 0.305,
      "step": 10500
    },
    {
      "epoch": 1.8927161822748475,
      "grad_norm": 5.134885787963867,
      "learning_rate": 1.0583888989007029e-05,
      "loss": 0.2054,
      "step": 10550
    },
    {
      "epoch": 1.901686401148188,
      "grad_norm": 0.9234815835952759,
      "learning_rate": 1.0538835826275004e-05,
      "loss": 0.2277,
      "step": 10600
    },
    {
      "epoch": 1.9106566200215285,
      "grad_norm": 1.1869803667068481,
      "learning_rate": 1.0493782663542982e-05,
      "loss": 0.1956,
      "step": 10650
    },
    {
      "epoch": 1.9196268388948692,
      "grad_norm": 0.1276799887418747,
      "learning_rate": 1.0448729500810957e-05,
      "loss": 0.2374,
      "step": 10700
    },
    {
      "epoch": 1.9285970577682097,
      "grad_norm": 23.366724014282227,
      "learning_rate": 1.0403676338078935e-05,
      "loss": 0.2504,
      "step": 10750
    },
    {
      "epoch": 1.9375672766415502,
      "grad_norm": 0.3076778054237366,
      "learning_rate": 1.0358623175346912e-05,
      "loss": 0.1925,
      "step": 10800
    },
    {
      "epoch": 1.9465374955148906,
      "grad_norm": 4.263909339904785,
      "learning_rate": 1.0313570012614886e-05,
      "loss": 0.2714,
      "step": 10850
    },
    {
      "epoch": 1.9555077143882311,
      "grad_norm": 3.5883045196533203,
      "learning_rate": 1.0268516849882863e-05,
      "loss": 0.2376,
      "step": 10900
    },
    {
      "epoch": 1.9644779332615716,
      "grad_norm": 0.7714520692825317,
      "learning_rate": 1.0223463687150838e-05,
      "loss": 0.214,
      "step": 10950
    },
    {
      "epoch": 1.973448152134912,
      "grad_norm": 0.36584141850471497,
      "learning_rate": 1.0178410524418816e-05,
      "loss": 0.1683,
      "step": 11000
    },
    {
      "epoch": 1.9824183710082526,
      "grad_norm": 10.911789894104004,
      "learning_rate": 1.0133357361686791e-05,
      "loss": 0.2266,
      "step": 11050
    },
    {
      "epoch": 1.991388589881593,
      "grad_norm": 5.768606662750244,
      "learning_rate": 1.0088304198954769e-05,
      "loss": 0.1711,
      "step": 11100
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9290455687118766,
      "eval_f1": 0.9297399887780607,
      "eval_loss": 0.24922406673431396,
      "eval_runtime": 928.6561,
      "eval_samples_per_second": 12.004,
      "eval_sentiment_accuracy": 0.9290455687118766,
      "eval_steps_per_second": 1.501,
      "step": 11148
    },
    {
      "epoch": 2.0003588087549335,
      "grad_norm": 0.24154989421367645,
      "learning_rate": 1.0043251036222742e-05,
      "loss": 0.2081,
      "step": 11150
    },
    {
      "epoch": 2.009329027628274,
      "grad_norm": 0.13190166652202606,
      "learning_rate": 9.99819787349072e-06,
      "loss": 0.1007,
      "step": 11200
    },
    {
      "epoch": 2.0182992465016145,
      "grad_norm": 5.545785903930664,
      "learning_rate": 9.953144710758697e-06,
      "loss": 0.2089,
      "step": 11250
    },
    {
      "epoch": 2.027269465374955,
      "grad_norm": 0.011490808799862862,
      "learning_rate": 9.908091548026673e-06,
      "loss": 0.1202,
      "step": 11300
    },
    {
      "epoch": 2.0362396842482955,
      "grad_norm": 0.19715291261672974,
      "learning_rate": 9.863038385294648e-06,
      "loss": 0.1391,
      "step": 11350
    },
    {
      "epoch": 2.045209903121636,
      "grad_norm": 8.653044700622559,
      "learning_rate": 9.817985222562625e-06,
      "loss": 0.2732,
      "step": 11400
    },
    {
      "epoch": 2.0541801219949765,
      "grad_norm": 0.136521115899086,
      "learning_rate": 9.772932059830601e-06,
      "loss": 0.1238,
      "step": 11450
    },
    {
      "epoch": 2.0631503408683174,
      "grad_norm": 4.911793231964111,
      "learning_rate": 9.727878897098576e-06,
      "loss": 0.2162,
      "step": 11500
    },
    {
      "epoch": 2.072120559741658,
      "grad_norm": 0.012147915549576283,
      "learning_rate": 9.682825734366554e-06,
      "loss": 0.1612,
      "step": 11550
    },
    {
      "epoch": 2.0810907786149984,
      "grad_norm": 15.673969268798828,
      "learning_rate": 9.63777257163453e-06,
      "loss": 0.1155,
      "step": 11600
    },
    {
      "epoch": 2.090060997488339,
      "grad_norm": 24.8382568359375,
      "learning_rate": 9.592719408902505e-06,
      "loss": 0.1324,
      "step": 11650
    },
    {
      "epoch": 2.0990312163616793,
      "grad_norm": 0.3408501446247101,
      "learning_rate": 9.547666246170482e-06,
      "loss": 0.1656,
      "step": 11700
    },
    {
      "epoch": 2.10800143523502,
      "grad_norm": 0.3505166172981262,
      "learning_rate": 9.502613083438458e-06,
      "loss": 0.1868,
      "step": 11750
    },
    {
      "epoch": 2.1169716541083603,
      "grad_norm": 0.8274891972541809,
      "learning_rate": 9.457559920706433e-06,
      "loss": 0.1609,
      "step": 11800
    },
    {
      "epoch": 2.125941872981701,
      "grad_norm": 8.163675308227539,
      "learning_rate": 9.41250675797441e-06,
      "loss": 0.1508,
      "step": 11850
    },
    {
      "epoch": 2.1349120918550413,
      "grad_norm": 7.1385416984558105,
      "learning_rate": 9.367453595242388e-06,
      "loss": 0.2183,
      "step": 11900
    },
    {
      "epoch": 2.1438823107283818,
      "grad_norm": 0.0169580839574337,
      "learning_rate": 9.322400432510363e-06,
      "loss": 0.1494,
      "step": 11950
    },
    {
      "epoch": 2.1528525296017222,
      "grad_norm": 31.142444610595703,
      "learning_rate": 9.277347269778339e-06,
      "loss": 0.1283,
      "step": 12000
    },
    {
      "epoch": 2.1618227484750627,
      "grad_norm": 0.28520238399505615,
      "learning_rate": 9.232294107046316e-06,
      "loss": 0.1549,
      "step": 12050
    },
    {
      "epoch": 2.170792967348403,
      "grad_norm": 0.572973370552063,
      "learning_rate": 9.187240944314292e-06,
      "loss": 0.1998,
      "step": 12100
    },
    {
      "epoch": 2.1797631862217437,
      "grad_norm": 0.5553526878356934,
      "learning_rate": 9.142187781582267e-06,
      "loss": 0.2739,
      "step": 12150
    },
    {
      "epoch": 2.188733405095084,
      "grad_norm": 0.22406239807605743,
      "learning_rate": 9.097134618850245e-06,
      "loss": 0.1623,
      "step": 12200
    },
    {
      "epoch": 2.1977036239684247,
      "grad_norm": 5.202558994293213,
      "learning_rate": 9.05208145611822e-06,
      "loss": 0.1699,
      "step": 12250
    },
    {
      "epoch": 2.206673842841765,
      "grad_norm": 8.51112174987793,
      "learning_rate": 9.007028293386196e-06,
      "loss": 0.1953,
      "step": 12300
    },
    {
      "epoch": 2.215644061715106,
      "grad_norm": 15.257819175720215,
      "learning_rate": 8.961975130654173e-06,
      "loss": 0.1817,
      "step": 12350
    },
    {
      "epoch": 2.2246142805884466,
      "grad_norm": 0.6980947256088257,
      "learning_rate": 8.916921967922149e-06,
      "loss": 0.2046,
      "step": 12400
    },
    {
      "epoch": 2.233584499461787,
      "grad_norm": 0.3552667498588562,
      "learning_rate": 8.871868805190124e-06,
      "loss": 0.1348,
      "step": 12450
    },
    {
      "epoch": 2.2425547183351275,
      "grad_norm": 0.10988084226846695,
      "learning_rate": 8.826815642458101e-06,
      "loss": 0.1848,
      "step": 12500
    },
    {
      "epoch": 2.251524937208468,
      "grad_norm": 10.698827743530273,
      "learning_rate": 8.781762479726077e-06,
      "loss": 0.1793,
      "step": 12550
    },
    {
      "epoch": 2.2604951560818085,
      "grad_norm": 0.30408617854118347,
      "learning_rate": 8.736709316994054e-06,
      "loss": 0.2095,
      "step": 12600
    },
    {
      "epoch": 2.269465374955149,
      "grad_norm": 23.626628875732422,
      "learning_rate": 8.69165615426203e-06,
      "loss": 0.1685,
      "step": 12650
    },
    {
      "epoch": 2.2784355938284895,
      "grad_norm": 0.5223109722137451,
      "learning_rate": 8.646602991530007e-06,
      "loss": 0.2313,
      "step": 12700
    },
    {
      "epoch": 2.28740581270183,
      "grad_norm": 0.07258493453264236,
      "learning_rate": 8.601549828797983e-06,
      "loss": 0.1713,
      "step": 12750
    },
    {
      "epoch": 2.2963760315751705,
      "grad_norm": 11.39499282836914,
      "learning_rate": 8.556496666065958e-06,
      "loss": 0.2158,
      "step": 12800
    },
    {
      "epoch": 2.305346250448511,
      "grad_norm": 0.07141801714897156,
      "learning_rate": 8.511443503333935e-06,
      "loss": 0.1549,
      "step": 12850
    },
    {
      "epoch": 2.3143164693218514,
      "grad_norm": 15.871623039245605,
      "learning_rate": 8.466390340601911e-06,
      "loss": 0.14,
      "step": 12900
    },
    {
      "epoch": 2.323286688195192,
      "grad_norm": 0.02270563133060932,
      "learning_rate": 8.421337177869887e-06,
      "loss": 0.1379,
      "step": 12950
    },
    {
      "epoch": 2.3322569070685324,
      "grad_norm": 0.006300212349742651,
      "learning_rate": 8.376284015137864e-06,
      "loss": 0.1743,
      "step": 13000
    },
    {
      "epoch": 2.341227125941873,
      "grad_norm": 0.3328792154788971,
      "learning_rate": 8.33123085240584e-06,
      "loss": 0.1392,
      "step": 13050
    },
    {
      "epoch": 2.3501973448152134,
      "grad_norm": 0.062170714139938354,
      "learning_rate": 8.286177689673815e-06,
      "loss": 0.1553,
      "step": 13100
    },
    {
      "epoch": 2.359167563688554,
      "grad_norm": 0.08261945843696594,
      "learning_rate": 8.241124526941792e-06,
      "loss": 0.2265,
      "step": 13150
    },
    {
      "epoch": 2.3681377825618943,
      "grad_norm": 0.14396098256111145,
      "learning_rate": 8.196071364209768e-06,
      "loss": 0.0858,
      "step": 13200
    },
    {
      "epoch": 2.377108001435235,
      "grad_norm": 0.07210124284029007,
      "learning_rate": 8.151018201477743e-06,
      "loss": 0.2215,
      "step": 13250
    },
    {
      "epoch": 2.3860782203085753,
      "grad_norm": 0.04598670080304146,
      "learning_rate": 8.10596503874572e-06,
      "loss": 0.1838,
      "step": 13300
    },
    {
      "epoch": 2.395048439181916,
      "grad_norm": 11.93347454071045,
      "learning_rate": 8.060911876013698e-06,
      "loss": 0.1534,
      "step": 13350
    },
    {
      "epoch": 2.4040186580552567,
      "grad_norm": 7.343723297119141,
      "learning_rate": 8.015858713281673e-06,
      "loss": 0.1956,
      "step": 13400
    },
    {
      "epoch": 2.412988876928597,
      "grad_norm": 0.18127425014972687,
      "learning_rate": 7.970805550549649e-06,
      "loss": 0.2036,
      "step": 13450
    },
    {
      "epoch": 2.4219590958019377,
      "grad_norm": 0.3630468547344208,
      "learning_rate": 7.925752387817626e-06,
      "loss": 0.119,
      "step": 13500
    },
    {
      "epoch": 2.430929314675278,
      "grad_norm": 14.402189254760742,
      "learning_rate": 7.880699225085602e-06,
      "loss": 0.1743,
      "step": 13550
    },
    {
      "epoch": 2.4398995335486187,
      "grad_norm": 0.2524891495704651,
      "learning_rate": 7.835646062353577e-06,
      "loss": 0.2019,
      "step": 13600
    },
    {
      "epoch": 2.448869752421959,
      "grad_norm": 10.57306957244873,
      "learning_rate": 7.790592899621555e-06,
      "loss": 0.1085,
      "step": 13650
    },
    {
      "epoch": 2.4578399712952996,
      "grad_norm": 7.537039279937744,
      "learning_rate": 7.74553973688953e-06,
      "loss": 0.1628,
      "step": 13700
    },
    {
      "epoch": 2.46681019016864,
      "grad_norm": 0.14175860583782196,
      "learning_rate": 7.700486574157506e-06,
      "loss": 0.222,
      "step": 13750
    },
    {
      "epoch": 2.4757804090419806,
      "grad_norm": 4.593723297119141,
      "learning_rate": 7.655433411425483e-06,
      "loss": 0.1039,
      "step": 13800
    },
    {
      "epoch": 2.484750627915321,
      "grad_norm": 0.13244329392910004,
      "learning_rate": 7.610380248693459e-06,
      "loss": 0.1448,
      "step": 13850
    },
    {
      "epoch": 2.4937208467886616,
      "grad_norm": 0.10029175132513046,
      "learning_rate": 7.565327085961435e-06,
      "loss": 0.1412,
      "step": 13900
    },
    {
      "epoch": 2.502691065662002,
      "grad_norm": 0.22058157622814178,
      "learning_rate": 7.520273923229411e-06,
      "loss": 0.1586,
      "step": 13950
    },
    {
      "epoch": 2.5116612845353425,
      "grad_norm": 0.036866653710603714,
      "learning_rate": 7.475220760497387e-06,
      "loss": 0.1002,
      "step": 14000
    },
    {
      "epoch": 2.520631503408683,
      "grad_norm": 0.02678936906158924,
      "learning_rate": 7.430167597765364e-06,
      "loss": 0.1571,
      "step": 14050
    },
    {
      "epoch": 2.529601722282024,
      "grad_norm": 0.05929328501224518,
      "learning_rate": 7.385114435033341e-06,
      "loss": 0.1706,
      "step": 14100
    },
    {
      "epoch": 2.5385719411553644,
      "grad_norm": 0.8282447457313538,
      "learning_rate": 7.340061272301316e-06,
      "loss": 0.1656,
      "step": 14150
    },
    {
      "epoch": 2.547542160028705,
      "grad_norm": 1.5717557668685913,
      "learning_rate": 7.295008109569293e-06,
      "loss": 0.1802,
      "step": 14200
    },
    {
      "epoch": 2.5565123789020454,
      "grad_norm": 0.05661493167281151,
      "learning_rate": 7.249954946837269e-06,
      "loss": 0.2202,
      "step": 14250
    },
    {
      "epoch": 2.565482597775386,
      "grad_norm": 8.179242134094238,
      "learning_rate": 7.204901784105245e-06,
      "loss": 0.1607,
      "step": 14300
    },
    {
      "epoch": 2.5744528166487264,
      "grad_norm": 0.06761568039655685,
      "learning_rate": 7.159848621373221e-06,
      "loss": 0.1697,
      "step": 14350
    },
    {
      "epoch": 2.583423035522067,
      "grad_norm": 0.06639145314693451,
      "learning_rate": 7.1147954586411975e-06,
      "loss": 0.157,
      "step": 14400
    },
    {
      "epoch": 2.5923932543954074,
      "grad_norm": 0.8339385390281677,
      "learning_rate": 7.069742295909173e-06,
      "loss": 0.1587,
      "step": 14450
    },
    {
      "epoch": 2.601363473268748,
      "grad_norm": 0.013265075162053108,
      "learning_rate": 7.0246891331771494e-06,
      "loss": 0.1386,
      "step": 14500
    },
    {
      "epoch": 2.6103336921420883,
      "grad_norm": 0.8062084317207336,
      "learning_rate": 6.979635970445126e-06,
      "loss": 0.1823,
      "step": 14550
    },
    {
      "epoch": 2.619303911015429,
      "grad_norm": 0.09055871516466141,
      "learning_rate": 6.9345828077131014e-06,
      "loss": 0.1893,
      "step": 14600
    },
    {
      "epoch": 2.6282741298887693,
      "grad_norm": 47.1165657043457,
      "learning_rate": 6.889529644981078e-06,
      "loss": 0.1374,
      "step": 14650
    },
    {
      "epoch": 2.63724434876211,
      "grad_norm": 4.221353530883789,
      "learning_rate": 6.844476482249054e-06,
      "loss": 0.1142,
      "step": 14700
    },
    {
      "epoch": 2.6462145676354503,
      "grad_norm": 4.7064619064331055,
      "learning_rate": 6.7994233195170315e-06,
      "loss": 0.1514,
      "step": 14750
    },
    {
      "epoch": 2.6551847865087908,
      "grad_norm": 0.17422692477703094,
      "learning_rate": 6.754370156785007e-06,
      "loss": 0.1755,
      "step": 14800
    },
    {
      "epoch": 2.6641550053821312,
      "grad_norm": 0.1302413046360016,
      "learning_rate": 6.7093169940529835e-06,
      "loss": 0.1646,
      "step": 14850
    },
    {
      "epoch": 2.6731252242554717,
      "grad_norm": 0.17578108608722687,
      "learning_rate": 6.66426383132096e-06,
      "loss": 0.1337,
      "step": 14900
    },
    {
      "epoch": 2.682095443128812,
      "grad_norm": 0.15115401148796082,
      "learning_rate": 6.6192106685889355e-06,
      "loss": 0.1698,
      "step": 14950
    },
    {
      "epoch": 2.6910656620021527,
      "grad_norm": 0.08721420913934708,
      "learning_rate": 6.574157505856912e-06,
      "loss": 0.1433,
      "step": 15000
    },
    {
      "epoch": 2.700035880875493,
      "grad_norm": 0.3884493410587311,
      "learning_rate": 6.529104343124888e-06,
      "loss": 0.165,
      "step": 15050
    },
    {
      "epoch": 2.7090060997488337,
      "grad_norm": 0.1440965086221695,
      "learning_rate": 6.484051180392864e-06,
      "loss": 0.2226,
      "step": 15100
    },
    {
      "epoch": 2.717976318622174,
      "grad_norm": 21.619417190551758,
      "learning_rate": 6.43899801766084e-06,
      "loss": 0.17,
      "step": 15150
    },
    {
      "epoch": 2.7269465374955146,
      "grad_norm": 0.08258114755153656,
      "learning_rate": 6.393944854928817e-06,
      "loss": 0.1372,
      "step": 15200
    },
    {
      "epoch": 2.7359167563688556,
      "grad_norm": 0.14704865217208862,
      "learning_rate": 6.348891692196792e-06,
      "loss": 0.1882,
      "step": 15250
    },
    {
      "epoch": 2.744886975242196,
      "grad_norm": 0.14613953232765198,
      "learning_rate": 6.303838529464769e-06,
      "loss": 0.1545,
      "step": 15300
    },
    {
      "epoch": 2.7538571941155365,
      "grad_norm": 0.04589026793837547,
      "learning_rate": 6.258785366732745e-06,
      "loss": 0.1822,
      "step": 15350
    },
    {
      "epoch": 2.762827412988877,
      "grad_norm": 4.370076656341553,
      "learning_rate": 6.213732204000721e-06,
      "loss": 0.1869,
      "step": 15400
    },
    {
      "epoch": 2.7717976318622175,
      "grad_norm": 30.060205459594727,
      "learning_rate": 6.168679041268698e-06,
      "loss": 0.1789,
      "step": 15450
    },
    {
      "epoch": 2.780767850735558,
      "grad_norm": 7.3858962059021,
      "learning_rate": 6.123625878536674e-06,
      "loss": 0.1281,
      "step": 15500
    },
    {
      "epoch": 2.7897380696088985,
      "grad_norm": 0.14012284576892853,
      "learning_rate": 6.078572715804651e-06,
      "loss": 0.1745,
      "step": 15550
    },
    {
      "epoch": 2.798708288482239,
      "grad_norm": 3.9600112438201904,
      "learning_rate": 6.033519553072626e-06,
      "loss": 0.1665,
      "step": 15600
    },
    {
      "epoch": 2.8076785073555794,
      "grad_norm": 4.526535987854004,
      "learning_rate": 5.988466390340603e-06,
      "loss": 0.1969,
      "step": 15650
    },
    {
      "epoch": 2.81664872622892,
      "grad_norm": 24.507164001464844,
      "learning_rate": 5.943413227608579e-06,
      "loss": 0.2088,
      "step": 15700
    },
    {
      "epoch": 2.8256189451022604,
      "grad_norm": 5.751698970794678,
      "learning_rate": 5.898360064876555e-06,
      "loss": 0.1684,
      "step": 15750
    },
    {
      "epoch": 2.834589163975601,
      "grad_norm": 5.629332542419434,
      "learning_rate": 5.853306902144531e-06,
      "loss": 0.1537,
      "step": 15800
    },
    {
      "epoch": 2.8435593828489414,
      "grad_norm": 13.7944917678833,
      "learning_rate": 5.8082537394125075e-06,
      "loss": 0.2428,
      "step": 15850
    },
    {
      "epoch": 2.852529601722282,
      "grad_norm": 0.9003415107727051,
      "learning_rate": 5.763200576680483e-06,
      "loss": 0.2166,
      "step": 15900
    },
    {
      "epoch": 2.861499820595623,
      "grad_norm": 7.75957727432251,
      "learning_rate": 5.7181474139484595e-06,
      "loss": 0.1436,
      "step": 15950
    },
    {
      "epoch": 2.8704700394689633,
      "grad_norm": 0.3752441704273224,
      "learning_rate": 5.673094251216436e-06,
      "loss": 0.1015,
      "step": 16000
    },
    {
      "epoch": 2.8794402583423038,
      "grad_norm": 13.63077449798584,
      "learning_rate": 5.6280410884844115e-06,
      "loss": 0.168,
      "step": 16050
    },
    {
      "epoch": 2.8884104772156443,
      "grad_norm": 0.8139139413833618,
      "learning_rate": 5.582987925752388e-06,
      "loss": 0.2362,
      "step": 16100
    },
    {
      "epoch": 2.8973806960889847,
      "grad_norm": 0.7634562849998474,
      "learning_rate": 5.537934763020365e-06,
      "loss": 0.1373,
      "step": 16150
    },
    {
      "epoch": 2.9063509149623252,
      "grad_norm": 0.07698703557252884,
      "learning_rate": 5.492881600288342e-06,
      "loss": 0.1025,
      "step": 16200
    },
    {
      "epoch": 2.9153211338356657,
      "grad_norm": 0.09587426483631134,
      "learning_rate": 5.447828437556317e-06,
      "loss": 0.1244,
      "step": 16250
    },
    {
      "epoch": 2.924291352709006,
      "grad_norm": 9.313141822814941,
      "learning_rate": 5.4027752748242936e-06,
      "loss": 0.1869,
      "step": 16300
    },
    {
      "epoch": 2.9332615715823467,
      "grad_norm": 0.13490155339241028,
      "learning_rate": 5.35772211209227e-06,
      "loss": 0.1376,
      "step": 16350
    },
    {
      "epoch": 2.942231790455687,
      "grad_norm": 0.5862557888031006,
      "learning_rate": 5.3126689493602455e-06,
      "loss": 0.1419,
      "step": 16400
    },
    {
      "epoch": 2.9512020093290277,
      "grad_norm": 0.0337693989276886,
      "learning_rate": 5.267615786628222e-06,
      "loss": 0.1415,
      "step": 16450
    },
    {
      "epoch": 2.960172228202368,
      "grad_norm": 0.8783935904502869,
      "learning_rate": 5.222562623896198e-06,
      "loss": 0.1955,
      "step": 16500
    },
    {
      "epoch": 2.9691424470757086,
      "grad_norm": 0.7986518740653992,
      "learning_rate": 5.177509461164174e-06,
      "loss": 0.2132,
      "step": 16550
    },
    {
      "epoch": 2.978112665949049,
      "grad_norm": 0.05984269455075264,
      "learning_rate": 5.13245629843215e-06,
      "loss": 0.212,
      "step": 16600
    },
    {
      "epoch": 2.9870828848223896,
      "grad_norm": 3.6567842960357666,
      "learning_rate": 5.087403135700127e-06,
      "loss": 0.225,
      "step": 16650
    },
    {
      "epoch": 2.99605310369573,
      "grad_norm": 4.649549961090088,
      "learning_rate": 5.042349972968102e-06,
      "loss": 0.2071,
      "step": 16700
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9340688912809473,
      "eval_f1": 0.9332280638746175,
      "eval_loss": 0.2663634717464447,
      "eval_runtime": 891.7508,
      "eval_samples_per_second": 12.501,
      "eval_sentiment_accuracy": 0.9340688912809473,
      "eval_steps_per_second": 1.563,
      "step": 16722
    },
    {
      "epoch": 3.0050233225690706,
      "grad_norm": 0.053181394934654236,
      "learning_rate": 4.997296810236079e-06,
      "loss": 0.1612,
      "step": 16750
    },
    {
      "epoch": 3.013993541442411,
      "grad_norm": 0.019338425248861313,
      "learning_rate": 4.952243647504055e-06,
      "loss": 0.0701,
      "step": 16800
    },
    {
      "epoch": 3.0229637603157515,
      "grad_norm": 0.008192678913474083,
      "learning_rate": 4.9071904847720316e-06,
      "loss": 0.0498,
      "step": 16850
    },
    {
      "epoch": 3.031933979189092,
      "grad_norm": 0.011303906328976154,
      "learning_rate": 4.862137322040007e-06,
      "loss": 0.0792,
      "step": 16900
    },
    {
      "epoch": 3.0409041980624325,
      "grad_norm": 0.30987775325775146,
      "learning_rate": 4.8170841593079835e-06,
      "loss": 0.1524,
      "step": 16950
    },
    {
      "epoch": 3.0498744169357734,
      "grad_norm": 0.00877675972878933,
      "learning_rate": 4.77203099657596e-06,
      "loss": 0.0995,
      "step": 17000
    },
    {
      "epoch": 3.058844635809114,
      "grad_norm": 4.545729637145996,
      "learning_rate": 4.726977833843936e-06,
      "loss": 0.1319,
      "step": 17050
    },
    {
      "epoch": 3.0678148546824544,
      "grad_norm": 27.024736404418945,
      "learning_rate": 4.681924671111913e-06,
      "loss": 0.098,
      "step": 17100
    },
    {
      "epoch": 3.076785073555795,
      "grad_norm": 0.16631610691547394,
      "learning_rate": 4.636871508379888e-06,
      "loss": 0.0838,
      "step": 17150
    },
    {
      "epoch": 3.0857552924291354,
      "grad_norm": 16.282411575317383,
      "learning_rate": 4.591818345647865e-06,
      "loss": 0.1909,
      "step": 17200
    },
    {
      "epoch": 3.094725511302476,
      "grad_norm": 7.527570724487305,
      "learning_rate": 4.546765182915841e-06,
      "loss": 0.2012,
      "step": 17250
    },
    {
      "epoch": 3.1036957301758163,
      "grad_norm": 0.3644031584262848,
      "learning_rate": 4.501712020183817e-06,
      "loss": 0.0553,
      "step": 17300
    },
    {
      "epoch": 3.112665949049157,
      "grad_norm": 0.383819043636322,
      "learning_rate": 4.456658857451793e-06,
      "loss": 0.1635,
      "step": 17350
    },
    {
      "epoch": 3.1216361679224973,
      "grad_norm": 0.04520599544048309,
      "learning_rate": 4.4116056947197696e-06,
      "loss": 0.1594,
      "step": 17400
    },
    {
      "epoch": 3.130606386795838,
      "grad_norm": 0.06294722110033035,
      "learning_rate": 4.366552531987746e-06,
      "loss": 0.1546,
      "step": 17450
    },
    {
      "epoch": 3.1395766056691783,
      "grad_norm": 0.5432933568954468,
      "learning_rate": 4.321499369255722e-06,
      "loss": 0.158,
      "step": 17500
    },
    {
      "epoch": 3.1485468245425188,
      "grad_norm": 0.03128202259540558,
      "learning_rate": 4.276446206523698e-06,
      "loss": 0.144,
      "step": 17550
    },
    {
      "epoch": 3.1575170434158593,
      "grad_norm": 9.343557357788086,
      "learning_rate": 4.231393043791674e-06,
      "loss": 0.1771,
      "step": 17600
    },
    {
      "epoch": 3.1664872622891997,
      "grad_norm": 0.28838422894477844,
      "learning_rate": 4.186339881059651e-06,
      "loss": 0.1014,
      "step": 17650
    },
    {
      "epoch": 3.1754574811625402,
      "grad_norm": 0.15519949793815613,
      "learning_rate": 4.141286718327626e-06,
      "loss": 0.0739,
      "step": 17700
    },
    {
      "epoch": 3.1844277000358807,
      "grad_norm": 0.004545578733086586,
      "learning_rate": 4.096233555595603e-06,
      "loss": 0.1005,
      "step": 17750
    },
    {
      "epoch": 3.193397918909221,
      "grad_norm": 9.23603343963623,
      "learning_rate": 4.051180392863579e-06,
      "loss": 0.1184,
      "step": 17800
    },
    {
      "epoch": 3.202368137782562,
      "grad_norm": 0.08860842138528824,
      "learning_rate": 4.006127230131556e-06,
      "loss": 0.1103,
      "step": 17850
    },
    {
      "epoch": 3.2113383566559026,
      "grad_norm": 4.128130912780762,
      "learning_rate": 3.961074067399532e-06,
      "loss": 0.1356,
      "step": 17900
    },
    {
      "epoch": 3.220308575529243,
      "grad_norm": 11.191084861755371,
      "learning_rate": 3.916020904667508e-06,
      "loss": 0.0873,
      "step": 17950
    },
    {
      "epoch": 3.2292787944025836,
      "grad_norm": 5.012165069580078,
      "learning_rate": 3.870967741935484e-06,
      "loss": 0.0787,
      "step": 18000
    },
    {
      "epoch": 3.238249013275924,
      "grad_norm": 0.1356794387102127,
      "learning_rate": 3.82591457920346e-06,
      "loss": 0.1339,
      "step": 18050
    },
    {
      "epoch": 3.2472192321492646,
      "grad_norm": 4.262887001037598,
      "learning_rate": 3.7808614164714364e-06,
      "loss": 0.1381,
      "step": 18100
    },
    {
      "epoch": 3.256189451022605,
      "grad_norm": 0.5796761512756348,
      "learning_rate": 3.7358082537394132e-06,
      "loss": 0.1801,
      "step": 18150
    },
    {
      "epoch": 3.2651596698959455,
      "grad_norm": 7.131022930145264,
      "learning_rate": 3.6907550910073892e-06,
      "loss": 0.0886,
      "step": 18200
    },
    {
      "epoch": 3.274129888769286,
      "grad_norm": 39.70020294189453,
      "learning_rate": 3.6457019282753652e-06,
      "loss": 0.1617,
      "step": 18250
    },
    {
      "epoch": 3.2831001076426265,
      "grad_norm": 0.14235323667526245,
      "learning_rate": 3.600648765543341e-06,
      "loss": 0.1502,
      "step": 18300
    },
    {
      "epoch": 3.292070326515967,
      "grad_norm": 0.06060308590531349,
      "learning_rate": 3.5555956028113176e-06,
      "loss": 0.0834,
      "step": 18350
    },
    {
      "epoch": 3.3010405453893075,
      "grad_norm": 80.0648193359375,
      "learning_rate": 3.5105424400792936e-06,
      "loss": 0.1335,
      "step": 18400
    },
    {
      "epoch": 3.310010764262648,
      "grad_norm": 10.599919319152832,
      "learning_rate": 3.4654892773472696e-06,
      "loss": 0.0996,
      "step": 18450
    },
    {
      "epoch": 3.3189809831359884,
      "grad_norm": 0.07716579735279083,
      "learning_rate": 3.4204361146152464e-06,
      "loss": 0.0802,
      "step": 18500
    },
    {
      "epoch": 3.327951202009329,
      "grad_norm": 9.292301177978516,
      "learning_rate": 3.3753829518832224e-06,
      "loss": 0.1419,
      "step": 18550
    },
    {
      "epoch": 3.3369214208826694,
      "grad_norm": 0.24212969839572906,
      "learning_rate": 3.330329789151199e-06,
      "loss": 0.1806,
      "step": 18600
    },
    {
      "epoch": 3.34589163975601,
      "grad_norm": 0.10611411184072495,
      "learning_rate": 3.285276626419175e-06,
      "loss": 0.1301,
      "step": 18650
    },
    {
      "epoch": 3.3548618586293504,
      "grad_norm": 0.13122501969337463,
      "learning_rate": 3.240223463687151e-06,
      "loss": 0.2038,
      "step": 18700
    },
    {
      "epoch": 3.363832077502691,
      "grad_norm": 0.18003617227077484,
      "learning_rate": 3.1951703009551272e-06,
      "loss": 0.1349,
      "step": 18750
    },
    {
      "epoch": 3.3728022963760314,
      "grad_norm": 26.42731285095215,
      "learning_rate": 3.1501171382231032e-06,
      "loss": 0.1118,
      "step": 18800
    },
    {
      "epoch": 3.381772515249372,
      "grad_norm": 0.1753319650888443,
      "learning_rate": 3.10506397549108e-06,
      "loss": 0.1357,
      "step": 18850
    },
    {
      "epoch": 3.3907427341227128,
      "grad_norm": 0.01837226003408432,
      "learning_rate": 3.060010812759056e-06,
      "loss": 0.0429,
      "step": 18900
    },
    {
      "epoch": 3.3997129529960533,
      "grad_norm": 0.10639055073261261,
      "learning_rate": 3.014957650027032e-06,
      "loss": 0.1132,
      "step": 18950
    },
    {
      "epoch": 3.4086831718693937,
      "grad_norm": 0.26812872290611267,
      "learning_rate": 2.9699044872950085e-06,
      "loss": 0.1189,
      "step": 19000
    },
    {
      "epoch": 3.417653390742734,
      "grad_norm": 0.25900906324386597,
      "learning_rate": 2.9248513245629844e-06,
      "loss": 0.1436,
      "step": 19050
    },
    {
      "epoch": 3.4266236096160747,
      "grad_norm": 0.13736318051815033,
      "learning_rate": 2.8797981618309604e-06,
      "loss": 0.1738,
      "step": 19100
    },
    {
      "epoch": 3.435593828489415,
      "grad_norm": 0.07340001314878464,
      "learning_rate": 2.834744999098937e-06,
      "loss": 0.1202,
      "step": 19150
    },
    {
      "epoch": 3.4445640473627557,
      "grad_norm": 0.553564727306366,
      "learning_rate": 2.7896918363669133e-06,
      "loss": 0.0914,
      "step": 19200
    },
    {
      "epoch": 3.453534266236096,
      "grad_norm": 0.1761876940727234,
      "learning_rate": 2.7446386736348897e-06,
      "loss": 0.1282,
      "step": 19250
    },
    {
      "epoch": 3.4625044851094366,
      "grad_norm": 0.12236375361680984,
      "learning_rate": 2.6995855109028657e-06,
      "loss": 0.0754,
      "step": 19300
    },
    {
      "epoch": 3.471474703982777,
      "grad_norm": 0.10935483127832413,
      "learning_rate": 2.6545323481708417e-06,
      "loss": 0.1831,
      "step": 19350
    },
    {
      "epoch": 3.4804449228561176,
      "grad_norm": 4.721634864807129,
      "learning_rate": 2.609479185438818e-06,
      "loss": 0.0735,
      "step": 19400
    },
    {
      "epoch": 3.489415141729458,
      "grad_norm": 0.02844017930328846,
      "learning_rate": 2.564426022706794e-06,
      "loss": 0.1545,
      "step": 19450
    },
    {
      "epoch": 3.4983853606027986,
      "grad_norm": 0.2524324059486389,
      "learning_rate": 2.51937285997477e-06,
      "loss": 0.0878,
      "step": 19500
    },
    {
      "epoch": 3.507355579476139,
      "grad_norm": 55.42087173461914,
      "learning_rate": 2.4743196972427465e-06,
      "loss": 0.2229,
      "step": 19550
    },
    {
      "epoch": 3.51632579834948,
      "grad_norm": 17.517074584960938,
      "learning_rate": 2.429266534510723e-06,
      "loss": 0.0945,
      "step": 19600
    },
    {
      "epoch": 3.5252960172228205,
      "grad_norm": 0.008546998724341393,
      "learning_rate": 2.3842133717786993e-06,
      "loss": 0.1343,
      "step": 19650
    },
    {
      "epoch": 3.534266236096161,
      "grad_norm": 0.005049625411629677,
      "learning_rate": 2.3391602090466753e-06,
      "loss": 0.0839,
      "step": 19700
    },
    {
      "epoch": 3.5432364549695015,
      "grad_norm": 0.18983811140060425,
      "learning_rate": 2.2941070463146513e-06,
      "loss": 0.106,
      "step": 19750
    },
    {
      "epoch": 3.552206673842842,
      "grad_norm": 0.01226740051060915,
      "learning_rate": 2.2490538835826277e-06,
      "loss": 0.114,
      "step": 19800
    },
    {
      "epoch": 3.5611768927161824,
      "grad_norm": 0.23823650181293488,
      "learning_rate": 2.204000720850604e-06,
      "loss": 0.0977,
      "step": 19850
    },
    {
      "epoch": 3.570147111589523,
      "grad_norm": 0.01340895239263773,
      "learning_rate": 2.15894755811858e-06,
      "loss": 0.1173,
      "step": 19900
    },
    {
      "epoch": 3.5791173304628634,
      "grad_norm": 18.689769744873047,
      "learning_rate": 2.113894395386556e-06,
      "loss": 0.2295,
      "step": 19950
    },
    {
      "epoch": 3.588087549336204,
      "grad_norm": 0.07002957165241241,
      "learning_rate": 2.0688412326545325e-06,
      "loss": 0.1701,
      "step": 20000
    },
    {
      "epoch": 3.5970577682095444,
      "grad_norm": 0.33491265773773193,
      "learning_rate": 2.023788069922509e-06,
      "loss": 0.0861,
      "step": 20050
    },
    {
      "epoch": 3.606027987082885,
      "grad_norm": 0.11230236291885376,
      "learning_rate": 1.978734907190485e-06,
      "loss": 0.103,
      "step": 20100
    },
    {
      "epoch": 3.6149982059562253,
      "grad_norm": 0.07375136017799377,
      "learning_rate": 1.933681744458461e-06,
      "loss": 0.097,
      "step": 20150
    },
    {
      "epoch": 3.623968424829566,
      "grad_norm": 0.05776853859424591,
      "learning_rate": 1.8886285817264375e-06,
      "loss": 0.1139,
      "step": 20200
    },
    {
      "epoch": 3.6329386437029063,
      "grad_norm": 0.11279866844415665,
      "learning_rate": 1.8435754189944135e-06,
      "loss": 0.1276,
      "step": 20250
    },
    {
      "epoch": 3.641908862576247,
      "grad_norm": 0.12175512313842773,
      "learning_rate": 1.7985222562623897e-06,
      "loss": 0.096,
      "step": 20300
    },
    {
      "epoch": 3.6508790814495873,
      "grad_norm": 0.7788641452789307,
      "learning_rate": 1.7534690935303661e-06,
      "loss": 0.1211,
      "step": 20350
    },
    {
      "epoch": 3.6598493003229278,
      "grad_norm": 3.9881625175476074,
      "learning_rate": 1.7084159307983423e-06,
      "loss": 0.151,
      "step": 20400
    },
    {
      "epoch": 3.6688195191962683,
      "grad_norm": 0.11873367428779602,
      "learning_rate": 1.6633627680663183e-06,
      "loss": 0.061,
      "step": 20450
    },
    {
      "epoch": 3.6777897380696087,
      "grad_norm": 1.953371524810791,
      "learning_rate": 1.6183096053342945e-06,
      "loss": 0.1136,
      "step": 20500
    },
    {
      "epoch": 3.6867599569429492,
      "grad_norm": 7.003014087677002,
      "learning_rate": 1.573256442602271e-06,
      "loss": 0.1464,
      "step": 20550
    },
    {
      "epoch": 3.6957301758162897,
      "grad_norm": 0.110006183385849,
      "learning_rate": 1.5282032798702471e-06,
      "loss": 0.1231,
      "step": 20600
    },
    {
      "epoch": 3.70470039468963,
      "grad_norm": 0.06916635483503342,
      "learning_rate": 1.4831501171382231e-06,
      "loss": 0.1605,
      "step": 20650
    },
    {
      "epoch": 3.7136706135629707,
      "grad_norm": 0.12400931864976883,
      "learning_rate": 1.4380969544061995e-06,
      "loss": 0.1278,
      "step": 20700
    },
    {
      "epoch": 3.7226408324363116,
      "grad_norm": 0.13521966338157654,
      "learning_rate": 1.3930437916741757e-06,
      "loss": 0.1768,
      "step": 20750
    },
    {
      "epoch": 3.731611051309652,
      "grad_norm": 58.10373306274414,
      "learning_rate": 1.3479906289421517e-06,
      "loss": 0.1127,
      "step": 20800
    },
    {
      "epoch": 3.7405812701829926,
      "grad_norm": 0.49386441707611084,
      "learning_rate": 1.302937466210128e-06,
      "loss": 0.1194,
      "step": 20850
    },
    {
      "epoch": 3.749551489056333,
      "grad_norm": 9.158363342285156,
      "learning_rate": 1.2578843034781043e-06,
      "loss": 0.1549,
      "step": 20900
    },
    {
      "epoch": 3.7585217079296735,
      "grad_norm": 0.3698866367340088,
      "learning_rate": 1.2128311407460805e-06,
      "loss": 0.193,
      "step": 20950
    },
    {
      "epoch": 3.767491926803014,
      "grad_norm": 0.19420012831687927,
      "learning_rate": 1.1677779780140565e-06,
      "loss": 0.1094,
      "step": 21000
    },
    {
      "epoch": 3.7764621456763545,
      "grad_norm": 4.511899471282959,
      "learning_rate": 1.122724815282033e-06,
      "loss": 0.1829,
      "step": 21050
    },
    {
      "epoch": 3.785432364549695,
      "grad_norm": 0.3842727541923523,
      "learning_rate": 1.0776716525500091e-06,
      "loss": 0.1549,
      "step": 21100
    },
    {
      "epoch": 3.7944025834230355,
      "grad_norm": 0.5083760619163513,
      "learning_rate": 1.0326184898179853e-06,
      "loss": 0.1603,
      "step": 21150
    },
    {
      "epoch": 3.803372802296376,
      "grad_norm": 46.85678482055664,
      "learning_rate": 9.875653270859615e-07,
      "loss": 0.0951,
      "step": 21200
    },
    {
      "epoch": 3.8123430211697165,
      "grad_norm": 0.13762883841991425,
      "learning_rate": 9.425121643539376e-07,
      "loss": 0.1547,
      "step": 21250
    },
    {
      "epoch": 3.821313240043057,
      "grad_norm": 0.1741737425327301,
      "learning_rate": 8.97459001621914e-07,
      "loss": 0.103,
      "step": 21300
    },
    {
      "epoch": 3.8302834589163974,
      "grad_norm": 0.1366753727197647,
      "learning_rate": 8.5240583888989e-07,
      "loss": 0.1121,
      "step": 21350
    },
    {
      "epoch": 3.839253677789738,
      "grad_norm": 0.3557415306568146,
      "learning_rate": 8.073526761578664e-07,
      "loss": 0.0767,
      "step": 21400
    },
    {
      "epoch": 3.848223896663079,
      "grad_norm": 0.12405071407556534,
      "learning_rate": 7.622995134258424e-07,
      "loss": 0.1027,
      "step": 21450
    },
    {
      "epoch": 3.8571941155364193,
      "grad_norm": 5.016580104827881,
      "learning_rate": 7.172463506938188e-07,
      "loss": 0.1534,
      "step": 21500
    },
    {
      "epoch": 3.86616433440976,
      "grad_norm": 5.04095983505249,
      "learning_rate": 6.721931879617951e-07,
      "loss": 0.0758,
      "step": 21550
    },
    {
      "epoch": 3.8751345532831003,
      "grad_norm": 0.27674397826194763,
      "learning_rate": 6.271400252297712e-07,
      "loss": 0.1316,
      "step": 21600
    },
    {
      "epoch": 3.884104772156441,
      "grad_norm": 4.595071792602539,
      "learning_rate": 5.820868624977474e-07,
      "loss": 0.0942,
      "step": 21650
    },
    {
      "epoch": 3.8930749910297813,
      "grad_norm": 0.09749568998813629,
      "learning_rate": 5.370336997657237e-07,
      "loss": 0.0999,
      "step": 21700
    },
    {
      "epoch": 3.9020452099031218,
      "grad_norm": 0.5084206461906433,
      "learning_rate": 4.919805370336999e-07,
      "loss": 0.1443,
      "step": 21750
    },
    {
      "epoch": 3.9110154287764622,
      "grad_norm": 0.14616574347019196,
      "learning_rate": 4.46927374301676e-07,
      "loss": 0.1576,
      "step": 21800
    },
    {
      "epoch": 3.9199856476498027,
      "grad_norm": 0.00606365455314517,
      "learning_rate": 4.018742115696522e-07,
      "loss": 0.1374,
      "step": 21850
    },
    {
      "epoch": 3.928955866523143,
      "grad_norm": 0.005627333652228117,
      "learning_rate": 3.568210488376284e-07,
      "loss": 0.1189,
      "step": 21900
    },
    {
      "epoch": 3.9379260853964837,
      "grad_norm": 0.022793101146817207,
      "learning_rate": 3.117678861056046e-07,
      "loss": 0.1335,
      "step": 21950
    },
    {
      "epoch": 3.946896304269824,
      "grad_norm": 0.006347629241645336,
      "learning_rate": 2.667147233735809e-07,
      "loss": 0.142,
      "step": 22000
    },
    {
      "epoch": 3.9558665231431647,
      "grad_norm": 0.06452268362045288,
      "learning_rate": 2.2166156064155706e-07,
      "loss": 0.1672,
      "step": 22050
    },
    {
      "epoch": 3.964836742016505,
      "grad_norm": 0.09838344901800156,
      "learning_rate": 1.7660839790953326e-07,
      "loss": 0.1274,
      "step": 22100
    },
    {
      "epoch": 3.9738069608898456,
      "grad_norm": 0.1893489956855774,
      "learning_rate": 1.3155523517750949e-07,
      "loss": 0.0965,
      "step": 22150
    },
    {
      "epoch": 3.982777179763186,
      "grad_norm": 0.08751377463340759,
      "learning_rate": 8.650207244548568e-08,
      "loss": 0.1321,
      "step": 22200
    },
    {
      "epoch": 3.9917473986365266,
      "grad_norm": 0.2632056772708893,
      "learning_rate": 4.144890971346189e-08,
      "loss": 0.1123,
      "step": 22250
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9303911015428776,
      "eval_f1": 0.9311121439202791,
      "eval_loss": 0.3228129744529724,
      "eval_runtime": 879.2327,
      "eval_samples_per_second": 12.679,
      "eval_sentiment_accuracy": 0.9303911015428776,
      "eval_steps_per_second": 1.585,
      "step": 22296
    }
  ],
  "logging_steps": 50,
  "max_steps": 22296,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.3465612313993216e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
