{
  "best_metric": 0.24108606576919556,
  "best_model_checkpoint": "/Users/deaxhavara/CyberPrint/models/deberta_active_learning_4epochs/checkpoint-5574",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 5574,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00897021887334051,
      "grad_norm": 2.702097177505493,
      "learning_rate": 1e-05,
      "loss": 1.3363,
      "step": 50
    },
    {
      "epoch": 0.01794043774668102,
      "grad_norm": 3.207737445831299,
      "learning_rate": 2e-05,
      "loss": 0.528,
      "step": 100
    },
    {
      "epoch": 0.02691065662002153,
      "grad_norm": 5.6960530281066895,
      "learning_rate": 1.995494683726798e-05,
      "loss": 0.4697,
      "step": 150
    },
    {
      "epoch": 0.03588087549336204,
      "grad_norm": 6.509079456329346,
      "learning_rate": 1.9909893674535953e-05,
      "loss": 0.4943,
      "step": 200
    },
    {
      "epoch": 0.044851094366702544,
      "grad_norm": 0.3150832951068878,
      "learning_rate": 1.986484051180393e-05,
      "loss": 0.4194,
      "step": 250
    },
    {
      "epoch": 0.05382131324004306,
      "grad_norm": 3.9901585578918457,
      "learning_rate": 1.9819787349071907e-05,
      "loss": 0.3837,
      "step": 300
    },
    {
      "epoch": 0.06279153211338356,
      "grad_norm": 2.65856671333313,
      "learning_rate": 1.9774734186339885e-05,
      "loss": 0.4311,
      "step": 350
    },
    {
      "epoch": 0.07176175098672408,
      "grad_norm": 1.8213614225387573,
      "learning_rate": 1.972968102360786e-05,
      "loss": 0.4034,
      "step": 400
    },
    {
      "epoch": 0.08073196986006459,
      "grad_norm": 1.6545324325561523,
      "learning_rate": 1.9684627860875836e-05,
      "loss": 0.3792,
      "step": 450
    },
    {
      "epoch": 0.08970218873340509,
      "grad_norm": 9.279109001159668,
      "learning_rate": 1.963957469814381e-05,
      "loss": 0.5063,
      "step": 500
    },
    {
      "epoch": 0.0986724076067456,
      "grad_norm": 4.558069229125977,
      "learning_rate": 1.9594521535411787e-05,
      "loss": 0.3963,
      "step": 550
    },
    {
      "epoch": 0.10764262648008611,
      "grad_norm": 2.799372673034668,
      "learning_rate": 1.9549468372679764e-05,
      "loss": 0.4119,
      "step": 600
    },
    {
      "epoch": 0.11661284535342663,
      "grad_norm": 0.18441073596477509,
      "learning_rate": 1.950441520994774e-05,
      "loss": 0.3782,
      "step": 650
    },
    {
      "epoch": 0.12558306422676713,
      "grad_norm": 1.4779454469680786,
      "learning_rate": 1.9459362047215715e-05,
      "loss": 0.5457,
      "step": 700
    },
    {
      "epoch": 0.13455328310010764,
      "grad_norm": 5.437480926513672,
      "learning_rate": 1.9414308884483692e-05,
      "loss": 0.3528,
      "step": 750
    },
    {
      "epoch": 0.14352350197344815,
      "grad_norm": 0.17237906157970428,
      "learning_rate": 1.9369255721751666e-05,
      "loss": 0.3172,
      "step": 800
    },
    {
      "epoch": 0.15249372084678867,
      "grad_norm": 0.48419803380966187,
      "learning_rate": 1.9324202559019644e-05,
      "loss": 0.3194,
      "step": 850
    },
    {
      "epoch": 0.16146393972012918,
      "grad_norm": 1.2063528299331665,
      "learning_rate": 1.927914939628762e-05,
      "loss": 0.4105,
      "step": 900
    },
    {
      "epoch": 0.1704341585934697,
      "grad_norm": 0.24722041189670563,
      "learning_rate": 1.9234096233555598e-05,
      "loss": 0.3918,
      "step": 950
    },
    {
      "epoch": 0.17940437746681018,
      "grad_norm": 1.0287683010101318,
      "learning_rate": 1.9189043070823575e-05,
      "loss": 0.4377,
      "step": 1000
    },
    {
      "epoch": 0.1883745963401507,
      "grad_norm": 1.5569299459457397,
      "learning_rate": 1.914398990809155e-05,
      "loss": 0.4732,
      "step": 1050
    },
    {
      "epoch": 0.1973448152134912,
      "grad_norm": 3.0380561351776123,
      "learning_rate": 1.9098936745359527e-05,
      "loss": 0.3297,
      "step": 1100
    },
    {
      "epoch": 0.20631503408683172,
      "grad_norm": 12.682655334472656,
      "learning_rate": 1.90538835826275e-05,
      "loss": 0.3495,
      "step": 1150
    },
    {
      "epoch": 0.21528525296017223,
      "grad_norm": 0.6852636933326721,
      "learning_rate": 1.9008830419895478e-05,
      "loss": 0.3232,
      "step": 1200
    },
    {
      "epoch": 0.22425547183351274,
      "grad_norm": 8.162595748901367,
      "learning_rate": 1.8963777257163455e-05,
      "loss": 0.2634,
      "step": 1250
    },
    {
      "epoch": 0.23322569070685326,
      "grad_norm": 3.178480625152588,
      "learning_rate": 1.8918724094431432e-05,
      "loss": 0.3669,
      "step": 1300
    },
    {
      "epoch": 0.24219590958019377,
      "grad_norm": 0.095413938164711,
      "learning_rate": 1.8873670931699406e-05,
      "loss": 0.2592,
      "step": 1350
    },
    {
      "epoch": 0.25116612845353425,
      "grad_norm": 14.163515090942383,
      "learning_rate": 1.8828617768967383e-05,
      "loss": 0.3767,
      "step": 1400
    },
    {
      "epoch": 0.2601363473268748,
      "grad_norm": 4.329550743103027,
      "learning_rate": 1.8783564606235357e-05,
      "loss": 0.3447,
      "step": 1450
    },
    {
      "epoch": 0.2691065662002153,
      "grad_norm": 2.2264509201049805,
      "learning_rate": 1.8738511443503334e-05,
      "loss": 0.3215,
      "step": 1500
    },
    {
      "epoch": 0.2780767850735558,
      "grad_norm": 0.618263304233551,
      "learning_rate": 1.8693458280771312e-05,
      "loss": 0.3377,
      "step": 1550
    },
    {
      "epoch": 0.2870470039468963,
      "grad_norm": 0.13868200778961182,
      "learning_rate": 1.864840511803929e-05,
      "loss": 0.3316,
      "step": 1600
    },
    {
      "epoch": 0.2960172228202368,
      "grad_norm": 0.24608953297138214,
      "learning_rate": 1.8603351955307266e-05,
      "loss": 0.3398,
      "step": 1650
    },
    {
      "epoch": 0.30498744169357733,
      "grad_norm": 18.889863967895508,
      "learning_rate": 1.855829879257524e-05,
      "loss": 0.3141,
      "step": 1700
    },
    {
      "epoch": 0.3139576605669178,
      "grad_norm": 2.6987342834472656,
      "learning_rate": 1.8513245629843217e-05,
      "loss": 0.2669,
      "step": 1750
    },
    {
      "epoch": 0.32292787944025836,
      "grad_norm": 6.051609516143799,
      "learning_rate": 1.846819246711119e-05,
      "loss": 0.3228,
      "step": 1800
    },
    {
      "epoch": 0.33189809831359884,
      "grad_norm": 1.0494860410690308,
      "learning_rate": 1.842313930437917e-05,
      "loss": 0.2983,
      "step": 1850
    },
    {
      "epoch": 0.3408683171869394,
      "grad_norm": 7.30696439743042,
      "learning_rate": 1.8378086141647146e-05,
      "loss": 0.3492,
      "step": 1900
    },
    {
      "epoch": 0.34983853606027987,
      "grad_norm": 17.686969757080078,
      "learning_rate": 1.8333032978915123e-05,
      "loss": 0.2673,
      "step": 1950
    },
    {
      "epoch": 0.35880875493362036,
      "grad_norm": 0.7223127484321594,
      "learning_rate": 1.8287979816183097e-05,
      "loss": 0.3028,
      "step": 2000
    },
    {
      "epoch": 0.3677789738069609,
      "grad_norm": 4.49629545211792,
      "learning_rate": 1.8242926653451074e-05,
      "loss": 0.2941,
      "step": 2050
    },
    {
      "epoch": 0.3767491926803014,
      "grad_norm": 0.6253957748413086,
      "learning_rate": 1.8197873490719048e-05,
      "loss": 0.2698,
      "step": 2100
    },
    {
      "epoch": 0.3857194115536419,
      "grad_norm": 8.131208419799805,
      "learning_rate": 1.8152820327987025e-05,
      "loss": 0.2908,
      "step": 2150
    },
    {
      "epoch": 0.3946896304269824,
      "grad_norm": 0.5654251575469971,
      "learning_rate": 1.8107767165255003e-05,
      "loss": 0.3161,
      "step": 2200
    },
    {
      "epoch": 0.40365984930032295,
      "grad_norm": 14.034560203552246,
      "learning_rate": 1.806271400252298e-05,
      "loss": 0.3605,
      "step": 2250
    },
    {
      "epoch": 0.41263006817366343,
      "grad_norm": 5.765153408050537,
      "learning_rate": 1.8017660839790957e-05,
      "loss": 0.2494,
      "step": 2300
    },
    {
      "epoch": 0.421600287047004,
      "grad_norm": 2.5934650897979736,
      "learning_rate": 1.797260767705893e-05,
      "loss": 0.3638,
      "step": 2350
    },
    {
      "epoch": 0.43057050592034446,
      "grad_norm": 7.210143089294434,
      "learning_rate": 1.7927554514326908e-05,
      "loss": 0.3307,
      "step": 2400
    },
    {
      "epoch": 0.43954072479368494,
      "grad_norm": 0.8090410232543945,
      "learning_rate": 1.7882501351594882e-05,
      "loss": 0.2957,
      "step": 2450
    },
    {
      "epoch": 0.4485109436670255,
      "grad_norm": 6.318236827850342,
      "learning_rate": 1.783744818886286e-05,
      "loss": 0.2441,
      "step": 2500
    },
    {
      "epoch": 0.45748116254036597,
      "grad_norm": 3.7241618633270264,
      "learning_rate": 1.7792395026130837e-05,
      "loss": 0.3036,
      "step": 2550
    },
    {
      "epoch": 0.4664513814137065,
      "grad_norm": 0.2737427055835724,
      "learning_rate": 1.7747341863398814e-05,
      "loss": 0.3124,
      "step": 2600
    },
    {
      "epoch": 0.475421600287047,
      "grad_norm": 5.6152119636535645,
      "learning_rate": 1.7702288700666788e-05,
      "loss": 0.2904,
      "step": 2650
    },
    {
      "epoch": 0.48439181916038754,
      "grad_norm": 8.91226577758789,
      "learning_rate": 1.7657235537934765e-05,
      "loss": 0.3072,
      "step": 2700
    },
    {
      "epoch": 0.493362038033728,
      "grad_norm": 0.635953426361084,
      "learning_rate": 1.761218237520274e-05,
      "loss": 0.2823,
      "step": 2750
    },
    {
      "epoch": 0.5023322569070685,
      "grad_norm": 24.113725662231445,
      "learning_rate": 1.7567129212470716e-05,
      "loss": 0.2841,
      "step": 2800
    },
    {
      "epoch": 0.511302475780409,
      "grad_norm": 3.823387384414673,
      "learning_rate": 1.7522076049738693e-05,
      "loss": 0.2927,
      "step": 2850
    },
    {
      "epoch": 0.5202726946537496,
      "grad_norm": 8.231597900390625,
      "learning_rate": 1.747702288700667e-05,
      "loss": 0.3121,
      "step": 2900
    },
    {
      "epoch": 0.5292429135270901,
      "grad_norm": 0.6271505355834961,
      "learning_rate": 1.7431969724274645e-05,
      "loss": 0.2318,
      "step": 2950
    },
    {
      "epoch": 0.5382131324004306,
      "grad_norm": 8.019207954406738,
      "learning_rate": 1.7386916561542622e-05,
      "loss": 0.3347,
      "step": 3000
    },
    {
      "epoch": 0.547183351273771,
      "grad_norm": 5.837894916534424,
      "learning_rate": 1.73418633988106e-05,
      "loss": 0.2254,
      "step": 3050
    },
    {
      "epoch": 0.5561535701471116,
      "grad_norm": 0.6247704029083252,
      "learning_rate": 1.7296810236078573e-05,
      "loss": 0.274,
      "step": 3100
    },
    {
      "epoch": 0.5651237890204521,
      "grad_norm": 14.416746139526367,
      "learning_rate": 1.725175707334655e-05,
      "loss": 0.2868,
      "step": 3150
    },
    {
      "epoch": 0.5740940078937926,
      "grad_norm": 0.12553977966308594,
      "learning_rate": 1.7206703910614527e-05,
      "loss": 0.304,
      "step": 3200
    },
    {
      "epoch": 0.5830642267671331,
      "grad_norm": 5.3339524269104,
      "learning_rate": 1.7161650747882505e-05,
      "loss": 0.2207,
      "step": 3250
    },
    {
      "epoch": 0.5920344456404736,
      "grad_norm": 0.5094115138053894,
      "learning_rate": 1.711659758515048e-05,
      "loss": 0.2867,
      "step": 3300
    },
    {
      "epoch": 0.6010046645138142,
      "grad_norm": 1.035821557044983,
      "learning_rate": 1.7071544422418456e-05,
      "loss": 0.276,
      "step": 3350
    },
    {
      "epoch": 0.6099748833871547,
      "grad_norm": 0.37231549620628357,
      "learning_rate": 1.702649125968643e-05,
      "loss": 0.3112,
      "step": 3400
    },
    {
      "epoch": 0.6189451022604952,
      "grad_norm": 3.5317745208740234,
      "learning_rate": 1.6981438096954407e-05,
      "loss": 0.2628,
      "step": 3450
    },
    {
      "epoch": 0.6279153211338356,
      "grad_norm": 0.9512822031974792,
      "learning_rate": 1.6936384934222384e-05,
      "loss": 0.2684,
      "step": 3500
    },
    {
      "epoch": 0.6368855400071761,
      "grad_norm": 14.220170974731445,
      "learning_rate": 1.689133177149036e-05,
      "loss": 0.2896,
      "step": 3550
    },
    {
      "epoch": 0.6458557588805167,
      "grad_norm": 4.559516429901123,
      "learning_rate": 1.6846278608758335e-05,
      "loss": 0.2514,
      "step": 3600
    },
    {
      "epoch": 0.6548259777538572,
      "grad_norm": 0.3705527186393738,
      "learning_rate": 1.6801225446026313e-05,
      "loss": 0.2397,
      "step": 3650
    },
    {
      "epoch": 0.6637961966271977,
      "grad_norm": 8.69636344909668,
      "learning_rate": 1.675617228329429e-05,
      "loss": 0.2556,
      "step": 3700
    },
    {
      "epoch": 0.6727664155005382,
      "grad_norm": 6.378554821014404,
      "learning_rate": 1.6711119120562264e-05,
      "loss": 0.255,
      "step": 3750
    },
    {
      "epoch": 0.6817366343738788,
      "grad_norm": 0.09609648585319519,
      "learning_rate": 1.666606595783024e-05,
      "loss": 0.2132,
      "step": 3800
    },
    {
      "epoch": 0.6907068532472193,
      "grad_norm": 0.2592240571975708,
      "learning_rate": 1.6621012795098218e-05,
      "loss": 0.2246,
      "step": 3850
    },
    {
      "epoch": 0.6996770721205597,
      "grad_norm": 11.132830619812012,
      "learning_rate": 1.6575959632366196e-05,
      "loss": 0.3281,
      "step": 3900
    },
    {
      "epoch": 0.7086472909939002,
      "grad_norm": 0.7787564992904663,
      "learning_rate": 1.653090646963417e-05,
      "loss": 0.3033,
      "step": 3950
    },
    {
      "epoch": 0.7176175098672407,
      "grad_norm": 0.18292640149593353,
      "learning_rate": 1.6485853306902147e-05,
      "loss": 0.2632,
      "step": 4000
    },
    {
      "epoch": 0.7265877287405813,
      "grad_norm": 5.6020894050598145,
      "learning_rate": 1.644080014417012e-05,
      "loss": 0.2889,
      "step": 4050
    },
    {
      "epoch": 0.7355579476139218,
      "grad_norm": 13.382370948791504,
      "learning_rate": 1.6395746981438098e-05,
      "loss": 0.2762,
      "step": 4100
    },
    {
      "epoch": 0.7445281664872623,
      "grad_norm": 0.7662826180458069,
      "learning_rate": 1.6350693818706075e-05,
      "loss": 0.1894,
      "step": 4150
    },
    {
      "epoch": 0.7534983853606028,
      "grad_norm": 4.966489791870117,
      "learning_rate": 1.6305640655974052e-05,
      "loss": 0.2468,
      "step": 4200
    },
    {
      "epoch": 0.7624686042339434,
      "grad_norm": 10.07754135131836,
      "learning_rate": 1.6260587493242026e-05,
      "loss": 0.2555,
      "step": 4250
    },
    {
      "epoch": 0.7714388231072838,
      "grad_norm": 14.49848461151123,
      "learning_rate": 1.6215534330510003e-05,
      "loss": 0.2958,
      "step": 4300
    },
    {
      "epoch": 0.7804090419806243,
      "grad_norm": 6.443771839141846,
      "learning_rate": 1.6170481167777977e-05,
      "loss": 0.3337,
      "step": 4350
    },
    {
      "epoch": 0.7893792608539648,
      "grad_norm": 0.08505465090274811,
      "learning_rate": 1.6125428005045955e-05,
      "loss": 0.2542,
      "step": 4400
    },
    {
      "epoch": 0.7983494797273053,
      "grad_norm": 1.369659185409546,
      "learning_rate": 1.6080374842313932e-05,
      "loss": 0.3351,
      "step": 4450
    },
    {
      "epoch": 0.8073196986006459,
      "grad_norm": 8.463960647583008,
      "learning_rate": 1.603532167958191e-05,
      "loss": 0.3074,
      "step": 4500
    },
    {
      "epoch": 0.8162899174739864,
      "grad_norm": 8.311412811279297,
      "learning_rate": 1.5990268516849886e-05,
      "loss": 0.3363,
      "step": 4550
    },
    {
      "epoch": 0.8252601363473269,
      "grad_norm": 0.8634010553359985,
      "learning_rate": 1.594521535411786e-05,
      "loss": 0.2241,
      "step": 4600
    },
    {
      "epoch": 0.8342303552206674,
      "grad_norm": 0.47254425287246704,
      "learning_rate": 1.5900162191385837e-05,
      "loss": 0.2477,
      "step": 4650
    },
    {
      "epoch": 0.843200574094008,
      "grad_norm": 7.443446636199951,
      "learning_rate": 1.585510902865381e-05,
      "loss": 0.2247,
      "step": 4700
    },
    {
      "epoch": 0.8521707929673484,
      "grad_norm": 12.395566940307617,
      "learning_rate": 1.581005586592179e-05,
      "loss": 0.249,
      "step": 4750
    },
    {
      "epoch": 0.8611410118406889,
      "grad_norm": 6.518298149108887,
      "learning_rate": 1.5765002703189766e-05,
      "loss": 0.2685,
      "step": 4800
    },
    {
      "epoch": 0.8701112307140294,
      "grad_norm": 1.4411507844924927,
      "learning_rate": 1.5719949540457743e-05,
      "loss": 0.2372,
      "step": 4850
    },
    {
      "epoch": 0.8790814495873699,
      "grad_norm": 0.5068363547325134,
      "learning_rate": 1.5674896377725717e-05,
      "loss": 0.2434,
      "step": 4900
    },
    {
      "epoch": 0.8880516684607105,
      "grad_norm": 1.7448986768722534,
      "learning_rate": 1.5629843214993694e-05,
      "loss": 0.3385,
      "step": 4950
    },
    {
      "epoch": 0.897021887334051,
      "grad_norm": 11.002448081970215,
      "learning_rate": 1.5584790052261668e-05,
      "loss": 0.2318,
      "step": 5000
    },
    {
      "epoch": 0.9059921062073915,
      "grad_norm": 0.07945325970649719,
      "learning_rate": 1.5539736889529645e-05,
      "loss": 0.2606,
      "step": 5050
    },
    {
      "epoch": 0.9149623250807319,
      "grad_norm": 4.8680572509765625,
      "learning_rate": 1.5494683726797623e-05,
      "loss": 0.3126,
      "step": 5100
    },
    {
      "epoch": 0.9239325439540724,
      "grad_norm": 10.44175910949707,
      "learning_rate": 1.54496305640656e-05,
      "loss": 0.2682,
      "step": 5150
    },
    {
      "epoch": 0.932902762827413,
      "grad_norm": 5.850577354431152,
      "learning_rate": 1.5404577401333577e-05,
      "loss": 0.1974,
      "step": 5200
    },
    {
      "epoch": 0.9418729817007535,
      "grad_norm": 5.697955131530762,
      "learning_rate": 1.535952423860155e-05,
      "loss": 0.2657,
      "step": 5250
    },
    {
      "epoch": 0.950843200574094,
      "grad_norm": 3.036616086959839,
      "learning_rate": 1.531447107586953e-05,
      "loss": 0.2068,
      "step": 5300
    },
    {
      "epoch": 0.9598134194474345,
      "grad_norm": 0.6340799331665039,
      "learning_rate": 1.5269417913137502e-05,
      "loss": 0.2728,
      "step": 5350
    },
    {
      "epoch": 0.9687836383207751,
      "grad_norm": 1.5117286443710327,
      "learning_rate": 1.5224364750405481e-05,
      "loss": 0.2254,
      "step": 5400
    },
    {
      "epoch": 0.9777538571941156,
      "grad_norm": 3.7969813346862793,
      "learning_rate": 1.5179311587673455e-05,
      "loss": 0.2808,
      "step": 5450
    },
    {
      "epoch": 0.986724076067456,
      "grad_norm": 5.875756740570068,
      "learning_rate": 1.5134258424941432e-05,
      "loss": 0.2528,
      "step": 5500
    },
    {
      "epoch": 0.9956942949407965,
      "grad_norm": 0.043137092143297195,
      "learning_rate": 1.5089205262209408e-05,
      "loss": 0.2065,
      "step": 5550
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9257265877287406,
      "eval_f1": 0.9271059693650966,
      "eval_loss": 0.24108606576919556,
      "eval_runtime": 1096.4788,
      "eval_samples_per_second": 10.167,
      "eval_sentiment_accuracy": 0.9257265877287406,
      "eval_steps_per_second": 1.271,
      "step": 5574
    }
  ],
  "logging_steps": 50,
  "max_steps": 22296,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5866403078498304.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
